{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Текущий план\n",
    "- Посчитать "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание задачи\n",
    "\n",
    "**Цель**: сделать веб-приложение, помогающее авторам и редакторам IT-публикаций подбирать к ним удачные заголовки.\n",
    "\n",
    "**Задача-минимум**: создать сервис, который учит пользователя (автора, редактора) использовать разумные подходы для составления говорящего заголовка. По такому заголовку читатель понимает, какую пользу он получит от прочтения статьи.\n",
    "\n",
    "**Идея MVP**. Проблему можно сформулировать в виде задачи распознавания именованных сущностей (англ. [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition), NER). Распознанные именованные сущности можно далее вмесе с токенизированным текстом использовать для выставления условного балла от 0 до 10, позволяющего автору быстро оценить результат.\n",
    "\n",
    "**Задача-минимум**: веб-страница, на которой пользователь вводит строку заголовка, а в ответ получает:\n",
    "1) оценка заголовка,\n",
    "2) найденные полезные индикаторы\n",
    "3) подсказки, что далее делать с заголовком.\n",
    "\n",
    "**Задача-максимум** (пока не решаем): генерация вариантов более качественных заголовков по тексту публикации или сочетанию чернового заголовка и краткого содержания.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструментарий\n",
    "- Python 3\n",
    "- NLP-библиотека [spaCy 3.0](https://spacy.io/). Мы выбрали `spacy` так как это стабильная библиотека, ориентированная на конечное использование в коммерческих приложениях. Однако 3-я версия не очень хорошо зарекомендовала для себя для классификации большого набора данных, а transformers оказалась слишком долгой для обучения и медленной для задачи веб-сервиса. Поэтому мы использовали быстрый CatBoost.\n",
    "- ML-библиотека CatBoost\n",
    "\n",
    "Для разметки эталонного набора именованных сущностей использовалось [Label Studio](https://labelstud.io/). Вручную было размечено 3000 заголовков, далее эти результаты использовались для полуавтоматической разметки. Для разметки данных мы использовали стандартный формат [CoNLL format](https://www.signll.org/conll/) ([StackOverflow discussion](https://stackoverflow.com/questions/27416164/what-is-conll-data-format))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import PIPE, run\n",
    "from itertools import combinations\n",
    "import json\n",
    "\n",
    "# библиотеки обработки данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# прогрессбар\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# natural language processing\n",
    "import spacy\n",
    "\n",
    "# ml models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, minmax_scale, quantile_transform\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# фильтрация некритичных предупреждений pandas b jupyter\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\",\n",
    "                      category=SettingWithCopyWarning)\n",
    "\n",
    "DATASETS_PATH = '../DATASETS/title'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка текстового корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Изучим датасет, содержащий заголовки и число просмотров\n",
    "\n",
    "С помощью веб-парсинга мы собрали большое количество данных в один общий датасет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df():\n",
    "    df = pd.read_feather(f'{DATASETS_PATH}/total.feather')    \n",
    "    df = df.set_index('url')  # feather doesn't work with str indices\n",
    "    \n",
    "    # parse timing cols ad datetime\n",
    "    for col in ('post_time', 'parse_time'):\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = read_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение статей по источникам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. ML-коррекция заниженного количества просмотров\n",
    "\n",
    "Количество просмотров на сайтах иногда значительно отстает от ожидаемого или не всегда рассчитывается правильно.\n",
    "\n",
    "Например, для новых статей или статей, изменивших статус публичности. Особенно это заметно, когда количество просмотров меньше количества лайков и закладок. Чтобы исправить такие значения, построим простую регрессионную модель на данных, которым мы можем доверять. Далее экстраполируем результат на «подозрительные» данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timedelta'] = (df.parse_time - df.post_time).apply(lambda x: x.total_seconds())*1e-6\n",
    "df_tmp = df[['likes_num', 'favs_num', 'comments_num', 'views_num', 'source', 'timedelta']].dropna()\n",
    "\n",
    "# for categorical data (source feature)\n",
    "df_tmp = pd.get_dummies(df_tmp)\n",
    "df_tmp['suspicious'] = [False]*df_tmp.shape[0]\n",
    "for col in ('likes', 'favs', 'comments'):\n",
    "    df_tmp['suspicious'] += df_tmp[f'{col}_num'] > 0.1*df_tmp['views_num']\n",
    "\n",
    "df_tmp_susp = df_tmp[df_tmp['suspicious'] == True]\n",
    "df_tmp = df_tmp[df_tmp['suspicious'] == False]\n",
    "\n",
    "df_tmp = df_tmp.drop(columns=['suspicious'])\n",
    "df_tmp_susp = df_tmp_susp.drop(columns=['suspicious'])\n",
    "\n",
    "y = df_tmp['views_num']\n",
    "X = df_tmp.drop(columns=['views_num'])\n",
    "reg = make_pipeline(StandardScaler(),\n",
    "                    RandomForestRegressor(n_jobs=20))\n",
    "reg.fit(X, y)\n",
    "df_tmp_susp['views_num'] = reg.predict(df_tmp_susp.drop(columns=['views_num']))\n",
    "df_tmp_susp['views_num'] = df_tmp_susp['views_num'].apply(round)\n",
    "df_tmp = pd.concat([df_tmp, df_tmp_susp])\n",
    "\n",
    "df.update(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем исключить данные, которые не содержат числа просмотров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['views_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы не будем учитывать сайт, на котором размещена публикация, поэтому нормируем число просмотров для статей определенного источника на максимальное для каждого из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in df.source.unique():\n",
    "    cond = (df.source == s)\n",
    "    m = df.loc[cond].views_num.max()\n",
    "    df.loc[cond, 'views_num'] /= m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Отбор признаков для работы\n",
    "\n",
    "**Число просмотров** — наша целевая переменная.\n",
    "\n",
    "**Время от публикации до парсинга**. Важной характеристикой публикации является то, когда она была опубликована. Тематики статей меняются, растет число людей с доступом в интернет. Со временем статьи с актуальными темами продолжают получать дочитывания, а наиболее новые статьи еще не набрали своего. В результате мы имеем следующее распределение просмотров относительно шкалы времени:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(-df.timedelta,\n",
    "            df.views_num,\n",
    "            s = 5,\n",
    "            marker='.')\n",
    "plt.xlabel('Время, усл. ед.')\n",
    "plt.ylabel('Число просмотров.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для новых публикаций мы будем указывать нулевую отметку времени.\n",
    "\n",
    "В результате мы используем сами тексты заголовков, число просмотров и интервал времени, за который число просмотров было набрано:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = df[['timedelta', 'title', 'views_num']].reset_index(drop=True)\n",
    "Xy.views_num = Xy.views_num.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Предобработка числовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью z-оценки выкинем явные выбросы (оказалось, что это примерно 5 тыс. статей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy['z_score'] = stats.zscore(Xy['views_num'])\n",
    "Xy = Xy.loc[Xy['z_score'].abs()<=3]\n",
    "Xy = Xy.drop(columns=['z_score'])\n",
    "Xy.reset_index(drop=True, inplace=True)\n",
    "print(Xy.shape)\n",
    "\n",
    "plt.scatter(-Xy.timedelta,\n",
    "            Xy.views_num,\n",
    "            s = 0.01,\n",
    "            marker='.')\n",
    "plt.xlabel('Время, усл. ед.')\n",
    "plt.ylabel('Число просмотров.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гистограмма распределния числа просмотров: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Xy.views_num, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кривая имеет предсказуемый характер, поэтому мы можем воспользоваться  преобразованием [Quantile Transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.quantile_transform.html#sklearn.preprocessing.quantile_transform), чтобы трансформировать распределение к нормальному виду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Xy.views_num.to_numpy().reshape(-1, 1)\n",
    "Xy['y'] = quantile_transform(y, output_distribution='normal')\n",
    "plt.hist(Xy['y'], bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для переменной времени применим обычную нормировку по интервалу, чтобы данные лежали в диапазоне `[0, 1]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.timedelta = minmax_scale(Xy.timedelta)\n",
    "plt.hist(Xy.timedelta, bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение модели распознавания именованных сущностей (модель NER)\n",
    "\n",
    "В качестве базовой модели `spacy` мы используем `ru_core_news_lg`. В ней уже имеются сущности `PER` (персоналий), организаций (`ORG`), географических локаций (`LOC`). Кроме имеющихся именованных сущностей мы добавили в разметку следующие категории и подкатегории:\n",
    "\n",
    "1. **Объект** `OBJ`. *О чём* эта статья.  Если заголовок состоит только из таких сущностей, значит перед нами что-то вроде статьи из словаря — объяснение сущности самого объекта. Примеры: \"LESS: программируемый язык стилей\", \"Composer — менеджер зависимостей для PHP\".\n",
    "2. **Аудитория** `AUD`. Для кого написан этот текст. Примеры индикаторов аудитории: \"для новичков, на Windows, профи, любой аккаунт, до 30 лет, русская версия\" Аудитория выражается и просто через \"я\" — мы сравниваем себя с другими людьми через наш общий или различный опыт. Наиболее читаемые статьи обращаются к аудитории новичков, но это не значит, что их читают только новички. \"Пайка для начинающих\", \"Hello World-проект на Flask\", \"Основы IP-телефонии\", \"Какой язык программирования стоит выучить пер\n",
    "вым?\".\n",
    "3. **Польза**. Какую проблему показывает или решает публикация. В чём ее профит?\n",
    "Польза может выражаться самыми разными способами:\n",
    "  + **Маркеры типа текста** `TYPE`: инструкция (\"как установить\", \"Шаблон базовой настройки маршрутизатора Cisco\"), определение (\"что такое... и с чем едят\"), новость (Новое в Java 8\"), личный опыт, сравнение объектов (\"X или Y\", \"Python vs R\") и т. д. По маркеру типа текста мы понимаем, с чем имеем дело.\n",
    "  + **Указание числа используемых источников или рассматриваемых объектов** `NUM`: \"10 лучших\", \"ТОП-3\".\n",
    "  + **Усилия и время, которые потратит читатель на саму статью или процесс** `EFFORT`: \"За 15 минут, за один вечер, за один год, краткое руководство, в 11 строчек кода\". Вполне возможно, что у человека достаточно времени, и он хочет детально во всём разобраться: \"Подробно о..., всё про...\". Главное, что вся нужная информация нашлась в одном месте.\n",
    "  + **Маркеры последовательного подхода, нового типа изложения** `STRUCT`. В интернете не хватает структурированной информации, люди любят когда рассказывают \"по порядку, детально, без воды\".\n",
    "  + **Предостережение об опасности или возможной ошибке** `DANGER`: \"Проблема в ... и ее их решение\", \"Взлом... от которого не спасёт\", \" \"X – ловушка для неопытных. Осторожно\".\n",
    "  + **Маркировка акта длинного повествования** `PART`. Указание части в заголовке подсказывает: перед нами часть большого текста. Хорошо работает следующий формат: \"Общее название группы технологий. Часть N. Название технологии.\"  Примеры: \"jQuery для начинающих. Часть 3. AJAX\". \"Bash-скрипты, часть 2: циклы\". \"Пишем игры на C++, Часть 1/3 — Написание мини-фреймворка\", \"Сети для самых маленьких. Часть шестая. Динамическая маршрутизация\".\n",
    "  + **Преимущество получаемое читателем**: бесплатно, своими руками, в домашних условиях\n",
    "4. **Источник движения** — в хороших статьях заложена история путешествия, они приводят читателя из пункта А в пункт Б. Саму историю расскажет статья, но полезно прочертить вектор с помощью глагола, или если придется к месту — искренней эмоции.\n",
    "  + **Побуждение к действию или само действие** `TODO`. Что мы будем делать в этой статье. \"Пишем программу...\", \"настройка, обзор, запуск, ремонт\". Примеры: \"Извлекаем золото из старой электроники\", \"Запуск старых игр на Windows\".\n",
    "  + **Эмоция** `EMO`. С эмоциями не стоит перебарщивать, но иногда сильная эмоция или выражение отношения — то, что нужно. \"Xудшее, что могло с нами случиться.\" \"Почему научиться программировать так чертовски тяжело?\". Помните: читатель не дурак, эмоции в заголовке работают только, если они неподдельные.\n",
    "\n",
    "Однако нужно помнить, что каким бы ни был заголовок, главное – сам текст и внимательное отношение к читателю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out(command):\n",
    "    '''Выводит данные '''\n",
    "    result = run(command, stdout=PIPE,\n",
    "                 stderr=PIPE, universal_newlines=True,\n",
    "                 shell=True)\n",
    "    return result.stdout\n",
    "\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"./ner_model/model-best\")\n",
    "except OSError:\n",
    "    # если модель ещё не обучалась\n",
    "    # используем в качестве старта предобученную\n",
    "    import ru_core_news_lg\n",
    "    nlp = ru_core_news_lg.load()\n",
    "    print(out(\"spacy init fill-config base_config.cfg config.cfg\"))\n",
    "    print(out(\"spacy convert ./train_data/title_ner.conll ./train_data/\"))\n",
    "    # это всего лишь прямой вызов из командной строки\n",
    "    !spacy train config.cfg --output ./ner_model --paths.train ./train_data/title_ner.spacy --paths.dev ./train_data/title_ner.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На нескольких примерах проверим корректность поиска именованных сущностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь применим NER-модель к текстовой составляющей — признаку `title`. Определим, какие сущности (`ents`) встречаются и какова их доля (`fraction`) от общей длины заголовка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_ents(s):\n",
    "    seq = nlp(s).ents\n",
    "    ents_list = [ent.label_ for ent in seq]\n",
    "    try:\n",
    "        fraction = len(''.join(str(ent) for ent in seq))/len(s)\n",
    "    except ZeroDivisionError:\n",
    "        fraction = 0.0\n",
    "    return ents_list, fraction\n",
    "\n",
    "\n",
    "try:\n",
    "    # распознавание сущностей для большого массива\n",
    "    # это трудоемкая операция, поэтому мы сохраняем результат\n",
    "    # и загружаем его, если уже был проведен расчет\n",
    "    Xy = pd.read_csv(f'{DATASETS_PATH}/Xy_ents.csv',\n",
    "                     index_col=0)\n",
    "    Xy.ents = Xy.ents.apply(eval)\n",
    "except FileNotFoundError:\n",
    "    Xy['ents'] = Xy.title.progress_apply(str_to_ents)\n",
    "    Xy['ents_fraction'] = Xy['ents'].apply(lambda x: x[1])\n",
    "    Xy['ents'] = Xy['ents'].apply(lambda x: x[0])\n",
    "    Xy.to_csv(f'{DATASETS_PATH}/Xy_ents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем полученные данные об именованных сущностях к числовому представлению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ee5c992bc144aab1b8617729177b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=306402.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>title</th>\n",
       "      <th>views_num</th>\n",
       "      <th>y</th>\n",
       "      <th>ents</th>\n",
       "      <th>ents_fraction</th>\n",
       "      <th>PER</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "      <th>OBJ</th>\n",
       "      <th>...</th>\n",
       "      <th>SITE</th>\n",
       "      <th>ANNOUNCE</th>\n",
       "      <th>MATH</th>\n",
       "      <th>GAME</th>\n",
       "      <th>NEWS</th>\n",
       "      <th>CONF</th>\n",
       "      <th>COND</th>\n",
       "      <th>APP</th>\n",
       "      <th>LIB</th>\n",
       "      <th>FRAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006861</td>\n",
       "      <td>Blackbox-сканеры в процессе оценки безопасност...</td>\n",
       "      <td>0.023319</td>\n",
       "      <td>1.959235</td>\n",
       "      <td>[DANGER]</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006972</td>\n",
       "      <td>Инструменты управления командой разработки на ...</td>\n",
       "      <td>0.058947</td>\n",
       "      <td>2.606826</td>\n",
       "      <td>[OBJ, OBJ, PUNCT, TYPE]</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006989</td>\n",
       "      <td>Стоит поиграть: обзор игры 7 Billion Humans</td>\n",
       "      <td>0.081565</td>\n",
       "      <td>2.938459</td>\n",
       "      <td>[TYPE, PUNCT, TYPE, OS]</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007087</td>\n",
       "      <td>Как снизить расходы на разработку программного...</td>\n",
       "      <td>0.078663</td>\n",
       "      <td>2.899126</td>\n",
       "      <td>[DANGER, DANGER, PUNCT]</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007103</td>\n",
       "      <td>Моя история в IT: от любви к математике до меж...</td>\n",
       "      <td>0.071457</td>\n",
       "      <td>2.783585</td>\n",
       "      <td>[TYPE, PUNCT, TYPE, VERSION, TYPE]</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta                                              title  views_num  \\\n",
       "0   0.006861  Blackbox-сканеры в процессе оценки безопасност...   0.023319   \n",
       "1   0.006972  Инструменты управления командой разработки на ...   0.058947   \n",
       "2   0.006989        Стоит поиграть: обзор игры 7 Billion Humans   0.081565   \n",
       "3   0.007087  Как снизить расходы на разработку программного...   0.078663   \n",
       "4   0.007103  Моя история в IT: от любви к математике до меж...   0.071457   \n",
       "\n",
       "          y                                ents  ents_fraction  PER  ORG  LOC  \\\n",
       "0  1.959235                            [DANGER]       0.517241    0    0    0   \n",
       "1  2.606826             [OBJ, OBJ, PUNCT, TYPE]       0.935897    0    0    0   \n",
       "2  2.938459             [TYPE, PUNCT, TYPE, OS]       0.604651    0    0    0   \n",
       "3  2.899126             [DANGER, DANGER, PUNCT]       0.932203    0    0    0   \n",
       "4  2.783585  [TYPE, PUNCT, TYPE, VERSION, TYPE]       0.829787    0    0    0   \n",
       "\n",
       "   OBJ  ...  SITE  ANNOUNCE  MATH  GAME  NEWS  CONF  COND  APP  LIB  FRAME  \n",
       "0    0  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "1    2  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "2    0  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "3    0  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "4    0  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в файле tags.json хранятся данные \n",
    "with open(f'{DATASETS_PATH}/tags.json') as f:\n",
    "    tags = json.load(f)\n",
    "\n",
    "# определим, какие сущности мы зарезервировали\n",
    "tag_names = [list(d.keys())[0] for d in tags]\n",
    "\n",
    "def ents_to_array(ents_list):\n",
    "    '''Преобразует список именованных сущностей\n",
    "    для одного заголовка в массив чисел,\n",
    "    где индекс соответствует номеру сущности,\n",
    "    а число - количеству появлений в заголовке'''\n",
    "    line = [0]*len(tag_names)\n",
    "    for t in ents_list:\n",
    "        try:\n",
    "            i = tag_names.index(t)\n",
    "            line[i] += 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return np.array(line, dtype=np.uint8)\n",
    "\n",
    "ents_array = Xy.ents.progress_apply(ents_to_array)\n",
    "data = np.array(ents_array.to_list())\n",
    "tmp = pd.DataFrame(data, columns=tag_names)\n",
    "Xy = pd.concat([Xy, tmp], axis = 1)\n",
    "Xy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на корреляцию признаков и числа просмотров `views_num` (без нелинейных преобразований `y`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "views_num        1.000000\n",
       "TYPE             0.067021\n",
       "AUD              0.059252\n",
       "NUM              0.058857\n",
       "TECH             0.033479\n",
       "ADV              0.028049\n",
       "OS               0.027734\n",
       "TODO             0.027263\n",
       "ents_fraction    0.025298\n",
       "APP              0.024423\n",
       "EFFORT           0.022167\n",
       "COND             0.020695\n",
       "DEVICE           0.020341\n",
       "EMO              0.015683\n",
       "MATH             0.014419\n",
       "OBJ              0.014397\n",
       "STRUCT           0.014030\n",
       "PART             0.013372\n",
       "LANG             0.012273\n",
       "LIB              0.009814\n",
       "FRAME            0.009645\n",
       "ORG              0.004831\n",
       "GAME             0.001097\n",
       "PER             -0.002634\n",
       "NEWS            -0.004132\n",
       "SITE            -0.004590\n",
       "ANNOUNCE        -0.004949\n",
       "CONF            -0.009781\n",
       "DANGER          -0.010112\n",
       "LOC             -0.013116\n",
       "PROGRAM         -0.018553\n",
       "timedelta       -0.144619\n",
       "Name: views_num, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = Xy.drop(columns=['y']).corr()\n",
    "correlations['views_num'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Относительно тегов мы можем предположить, что указание типа (`TYPE`),  используемой технологии (`TECH`), целевой аудитории `AUD` и совершаемого действия (`TODO`) обычно приводят к увеличению числа просмотров.\n",
    "\n",
    "Указание опасности (`DANGER`), организации, персоны, локации (`ORG`, `PER`, `LOC`), конкретной программы (`PROGRAM`), конференции (`CONF`),видимо, в большей мере относятся к новостям, которые быстро теряют актуальности. Поэтому такие атрибуты связаны с уменьшением количества просмотров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.drop(columns=['title', 'views_num', 'ents', 'y'])\n",
    "y = Xy.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сами корреляции коэффициенты корреляции в абсолютном значении невелики. Поэтому большее внимание надо отдавать языковой модели. Предварительно попробуем поискать композитные фичи, используя пары и тройки столбцов с тегами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ents = X.drop(columns=['timedelta', 'ents_fraction'])\n",
    "from itertools import combinations\n",
    "\n",
    "cc2 = list(combinations(X_ents.columns,2))\n",
    "X_ents2 = pd.concat([X_ents[c[0]].add(X_ents[c[1]]) for c in cc2],\n",
    "          axis=1, keys=cc2)\n",
    "\n",
    "cc3 = list(combinations(X_ents.columns,3))\n",
    "X_ents3 = pd.concat([X_ents[c[0]].add(X_ents[c[1]]).add(X_ents[c[2]]) for c in cc3],\n",
    "          axis=1, keys=cc3)\n",
    "\n",
    "X_ents2.columns = X_ents2.columns.map('_'.join)\n",
    "X_ents3.columns = X_ents3.columns.map('_'.join)\n",
    "X_ents = pd.concat([X, X_ents2, X_ents3, Xy['views_num']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "X_ents = X_ents.fillna(0)\n",
    "X_ents['BOOL'] = X.ents_fraction.apply(lambda x: x == 0)\n",
    "for col in X_ents.drop(columns=['views_num', 'timedelta', 'ents_fraction']).columns:\n",
    "    d[col] = stats.pearsonr(X_ents['views_num'], X_ents[col])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list, value_list = [], []\n",
    "\n",
    "for key in d:\n",
    "    ner_list.append(set(key.split('_')))\n",
    "    value_list.append(d[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_cor = pd.DataFrame.from_dict({'NER': ner_list, 'VALUE': value_list})\n",
    "df_ner_cor.to_csv(f'{DATASETS_PATH}/df_ner_cor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>{'TYPE', 'AUD', 'NUM'}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>{'TYPE', 'AUD', 'TODO'}</td>\n",
       "      <td>0.957262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>{'TYPE', 'AUD', 'ADV'}</td>\n",
       "      <td>0.950282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>{'TYPE', 'AUD', 'OS'}</td>\n",
       "      <td>0.949277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>{'TYPE', 'TECH', 'AUD'}</td>\n",
       "      <td>0.946819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>{'DANGER', 'PROGRAM', 'LOC'}</td>\n",
       "      <td>0.051112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>{'NEWS', 'PROGRAM', 'LOC'}</td>\n",
       "      <td>0.050469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>{'ANNOUNCE', 'PROGRAM', 'LOC'}</td>\n",
       "      <td>0.049296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>{'PROGRAM', 'LOC', 'CONF'}</td>\n",
       "      <td>0.042589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>{'BOOL'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 NER     VALUE\n",
       "1789          {'TYPE', 'AUD', 'NUM'}  1.000000\n",
       "1794         {'TYPE', 'AUD', 'TODO'}  0.957262\n",
       "1796          {'TYPE', 'AUD', 'ADV'}  0.950282\n",
       "1799           {'TYPE', 'AUD', 'OS'}  0.949277\n",
       "1798         {'TYPE', 'TECH', 'AUD'}  0.946819\n",
       "...                              ...       ...\n",
       "1306    {'DANGER', 'PROGRAM', 'LOC'}  0.051112\n",
       "1428      {'NEWS', 'PROGRAM', 'LOC'}  0.050469\n",
       "1425  {'ANNOUNCE', 'PROGRAM', 'LOC'}  0.049296\n",
       "1429      {'PROGRAM', 'LOC', 'CONF'}  0.042589\n",
       "4089                        {'BOOL'}  0.000000\n",
       "\n",
       "[4090 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner_cor.sort_values(by='VALUE', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метке `BOOL` соответствует полное отсутствие каких-либо сущностей. Таким образом, хотя бы минимальное соответствие, даже худшим по корреляциям из меток, лучше, чем ничего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Обучение регрессионной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы привели текстовые данные к числовому представлению и теперь можем заняться задачей регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ents.drop(columns=['views_num']), y,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении используем структуру `Pool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 10000,\n",
    "    'learning_rate': 0.01,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'early_stopping_rounds': 100,\n",
    "    'use_best_model': True\n",
    "}\n",
    "\n",
    "def fit_model(X_train, y_train, X_test, y_test, catboost_params):\n",
    "    train_pool = Pool(data = X_train,\n",
    "                      label = y_train)\n",
    "\n",
    "    validation_pool = Pool(data = X_test,\n",
    "                           label = y_test)\n",
    "\n",
    "    model = CatBoostRegressor(**catboost_params)\n",
    "\n",
    "    return model.fit(train_pool,\n",
    "                     eval_set=validation_pool,\n",
    "                     verbose=100)\n",
    "\n",
    "\n",
    "model = fit_model(X_train, y_train,\n",
    "                  X_test, y_test,\n",
    "                  catboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE(model.predict(X_test), y_test))\n",
    "plt.scatter(model.predict(X_test), y_test, s=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вполне ожидаемо (и прискорбно), но регресионная модель обучается довольно слабо: на число просмотров оказывают влияния множество иных факторов, а не только сами сущности.\n",
    "\n",
    "Использование трансформерной модели или других моделей, работающих с сутью текста, повысило бы качество, но усложнило бы коррекцию заголовка пользователем: балл оценки в таком случае сложно интерпретируется, возможны только действия \"наугад\". Однако такое решение можно использовать в будущем для генеративного подхода поиска заголовка.\n",
    "\n",
    "Поэтому мы воспользуемся подходом программного определения правил, исходя из лучших сочетаний сущностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Упрощенная корреляционная модель\n",
    "\n",
    "Напишем функцию, которая принимает на вход строку, а на выходе возвращает рекомендации для коррекции заголовка. Для этого нам понадобится несколько вспомогательных функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>{AUD, TYPE, NUM}</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>{AUD, TYPE, TODO}</td>\n",
       "      <td>9.6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>{ADV, AUD, TYPE}</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>{OS, AUD, TYPE}</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>{AUD, TYPE, TECH}</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>{DANGER, PROGRAM, LOC}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>{NEWS, PROGRAM, LOC}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>{ANNOUNCE, PROGRAM, LOC}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>{CONF, PROGRAM, LOC}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>{BOOL}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4090 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NER  VALUE  LEN\n",
       "1789          {AUD, TYPE, NUM}   10.0    3\n",
       "1794         {AUD, TYPE, TODO}    9.6    3\n",
       "1796          {ADV, AUD, TYPE}    9.5    3\n",
       "1799           {OS, AUD, TYPE}    9.5    3\n",
       "1798         {AUD, TYPE, TECH}    9.5    3\n",
       "...                        ...    ...  ...\n",
       "1306    {DANGER, PROGRAM, LOC}    0.5    3\n",
       "1428      {NEWS, PROGRAM, LOC}    0.5    3\n",
       "1425  {ANNOUNCE, PROGRAM, LOC}    0.5    3\n",
       "1429      {CONF, PROGRAM, LOC}    0.4    3\n",
       "4089                    {BOOL}    0.0    1\n",
       "\n",
       "[4090 rows x 3 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DATASETS_PATH}/df_ner_cor.csv',\n",
    "                         index_col=0)\n",
    "\n",
    "# преобразуем строки к множествам\n",
    "df.NER = df.NER.apply(eval)\n",
    "\n",
    "# нормировка диапазона между 0 и 1. \n",
    "df.VALUE = minmax_scale(df_ner_cor.VALUE)\n",
    "\n",
    "df = df.sort_values(by='VALUE', ascending=False)\n",
    "\n",
    "# приведем значения к десятибалльной шкале\n",
    "# с точностью 0.1\n",
    "df.VALUE = df.VALUE.apply(lambda x: 10*round(x, 2))\n",
    "\n",
    "# подсчитываем количество вхождений\n",
    "# для дальнейшего удобства отбора\n",
    "df['LEN'] = df.NER.apply(len)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим возможные варианты:\n",
    "1. **Строка заголовка пустая**. Отображаем подсказку, что заголовок нужно ввести.\n",
    "2. **Строка заголовка непустая, но мы не распознали сущности**. Выставляем 0 баллов. Мягко предлагаем переформулировать заголовок, подумать над темой или отправить нам заголовок, чтобы мы доразметили набор данных.\n",
    "3. **Найдена 1 сущность**. В каждом случае, когда распознана сущность, выставляем балл и предлагаем возможное улучшение. Для этого смотрим, в каких случаях была\n",
    "4. **Найдены 2 сущности**. \n",
    "5. **Найдены 3 сущности**. \n",
    "6. **Найдено более 3 сущностей**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1\n",
      "OrderedDict([('AUD', 8.9), ('TYPE', 8.5), ('NUM', 8.2), ('TECH', 8.100000000000001), ('TODO', 8.100000000000001), ('OS', 8.0), ('ADV', 8.0), ('DEVICE', 7.800000000000001), ('EFFORT', 7.7), ('APP', 7.7), ('EMO', 7.7), ('COND', 7.6), ('MATH', 7.6), ('STRUCT', 7.5), ('LIB', 7.5), ('FRAME', 7.5), ('LANG', 7.5), ('PART', 7.5), ('GAME', 7.5), ('NEWS', 7.5), ('ANNOUNCE', 7.4), ('CONF', 7.4), ('SITE', 7.4), ('OBJ', 7.3), ('LOC', 7.199999999999999), ('ORG', 7.1), ('DANGER', 7.1), ('PROGRAM', 7.0)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rating': 2.1,\n",
       " 'comment': 'Заголовок получил низкую оценку.',\n",
       " 'suggestion_start': 'Попробуйте указать '}"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def find_value(ner_set, df=df):\n",
    "    \"\"\"Находит числовое значение,\n",
    "    соответствующее набору именованных сущностей\"\"\"\n",
    "    if len(ner_set) <= 3:\n",
    "        cond = (df.NER == ner_set, 'VALUE')\n",
    "        try:\n",
    "            value = df.loc[cond].values[0]\n",
    "        except IndexError:\n",
    "            value = 0.0\n",
    "    else:\n",
    "        cs = combinations(ner_set, 3)\n",
    "        best_value = 0.0\n",
    "        best_triad = set()\n",
    "        for c in cs:\n",
    "            v = find_value(set(c))\n",
    "            if v > best_value:\n",
    "                best_triad = c\n",
    "                best_value = v\n",
    "        value = best_value\n",
    "    return value\n",
    "\n",
    "\n",
    "def find_set_with_greater_value(subset, df=df, exclude={}):\n",
    "    \"\"\"Возвращает полный список сущностей,\n",
    "    добавление которых к subset повышает оценку value\"\"\"\n",
    "    \n",
    "    value = find_value(subset)        \n",
    "    cond = df.apply(lambda x: (subset.issubset(x.NER) and (x.VALUE > value)),\n",
    "                    axis=1)\n",
    "    ners = df[cond].NER.to_list()\n",
    "    values = df[cond].VALUE.to_list()\n",
    "    suggestions = []\n",
    "    for triad in ners:\n",
    "        # выкидываем имеющиеся 1 или 2 тега\n",
    "        # и добавляем те, что их дополняют\n",
    "        s = triad-subset\n",
    "        for item in s:\n",
    "            if item not in suggestions and item not in exclude:\n",
    "                suggestions.append(item)\n",
    "    return OrderedDict(zip(suggestions, values))\n",
    "\n",
    "\n",
    "def highlight_best_pair(subset, df=df):\n",
    "    \"\"\"Находит пару с лучшими возможностями для\n",
    "    расширения\"\"\"\n",
    "    \n",
    "    L = [set(pair) for pair in combinations(subset, 2)]\n",
    "    value_max = 0 \n",
    "    pair_max = {}\n",
    "    \n",
    "    for pair in L:\n",
    "        ordered_dict = find_set_with_greater_value(pair)\n",
    "        for i in subset - pair:\n",
    "            ordered_dict.pop(i, None)\n",
    "        best_ner = next(iter(ordered_dict))\n",
    "        total_max = ordered_dict[best_ner]\n",
    "        if total_max > value_max:\n",
    "            pair_max = pair\n",
    "\n",
    "    # остальные сущности запомним, чтобы не предлагать\n",
    "    others = subset - pair_max\n",
    "    return {'best_pair': pair_max,\n",
    "            'others': others}\n",
    "\n",
    "\n",
    "def suggest(subset, df=df):\n",
    "    \"\"\"Определяет предложение пользователю\n",
    "    для текущего набора именованных сущностей subset\"\"\"\n",
    "    if len(subset) < 3:\n",
    "        od = find_set_with_greater_value(subset)\n",
    "    else:\n",
    "        h = highlight_best_pair(subset)\n",
    "        pair = h['best_pair']\n",
    "        others = h['others']\n",
    "        od = find_set_with_greater_value(pair, exclude=others)\n",
    "    return od\n",
    "\n",
    "\n",
    "def human_suggest(subset, df=df):\n",
    "    \"\"\"Возвращает строки, которые мы показываем пользователю\"\"\"\n",
    "    value = find_value(s)\n",
    "    suggestion_start = \"Попробуйте указать \"\n",
    "    if len(subset) == 0:\n",
    "        comment = \"Мы не смогли распознать сущностей, характерных для IT-статей.\"\n",
    "        value == 0.0\n",
    "    elif 0.0 < value <= 5.0:\n",
    "        comment = \"Заголовок получил низкую оценку.\"\n",
    "        if len(subset) >= 3:\n",
    "            comment += f\" Хотя мы распознали несколько индикаторов, \" \\\n",
    "            \"все они относятся к малочитаемым публикациям.\"\n",
    "    elif 5.0 < value <= 9.0:\n",
    "        comment = \"Достаточно хороший заголовок для IT-статьи.\"\n",
    "        suggestion_start = \"Чтобы его улучшить, укажите \"\n",
    "    elif 9.0 < value < 10.0:\n",
    "        comment = \"Отличный заголовок для IT-публикации!\"\n",
    "    elif value == 10.0:\n",
    "        comment = \"Поздравляем! Заголовок набрал максимально возможный балл — 10 из 10.\"   \n",
    "    return {'rating': value,\n",
    "            'comment': comment,\n",
    "            'suggestion_start': suggestion_start}\n",
    "\n",
    "\n",
    "s = {'PER',}\n",
    "print(find_value(s))\n",
    "print(suggest(s)) \n",
    "human_suggest(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PER': {'definition': 'Известная персона',\n",
       "   'examples': ['Дональд Кнут', 'Илон Маск'],\n",
       "   'accusative': ['персону']}},\n",
       " {'ORG': {'definition': 'Организация, компания',\n",
       "   'examples': ['Apple', 'NASA'],\n",
       "   'accusative': ['организацию', 'компанию']}},\n",
       " {'LOC': {'definition': 'Географическая локация, местоположение',\n",
       "   'examples': ['в Санкт-Петербурге', 'в России'],\n",
       "   'accusative': ['место', 'локацию']}},\n",
       " {'OBJ': {'definition': 'Неспецифичный объект, встречающийся в заголовках IT-статей',\n",
       "   'examples': ['мобильная связь', 'электронное мисьмо'],\n",
       "   'accusative': ['объект, о котором идет речь']}},\n",
       " {'AUD': {'definition': 'Аудитория. Для кого предназначена публикация',\n",
       "   'examples': ['для новичков', 'для профи', 'до 30 лет', 'русская версия'],\n",
       "   'accusative': ['аудиторию']}},\n",
       " {'TYPE': {'definition': 'Маркер типа текста. По такому маркеру читатели понимают, с каким текстом имеют дело.',\n",
       "   'examples': ['инструкция', 'как установить...', 'что такое...', 'X vs Y'],\n",
       "   'accusative': ['тип публикации', 'тип текста']}},\n",
       " {'NUM': {'definition': 'Указание числа используемых источников или рассматриваемых объектов',\n",
       "   'examples': ['10 лучших', 'ТОП-3'],\n",
       "   'accusative': ['число рассматриваемых объектов']}},\n",
       " {'EFFORT': {'definition': 'Усилия и время, которые читатель потратит на статью или процесс',\n",
       "   'examples': ['за 15 минут',\n",
       "    'за один вечер',\n",
       "    'за год',\n",
       "    'краткое руководство'],\n",
       "   'accusative': ['какие усилия или какое время затратит читатель']}},\n",
       " {'STRUCT': {'definition': 'Маркер последовательного подхода или нового типа изложения.',\n",
       "   'examples': ['по порядку', 'детально', 'без воды'],\n",
       "   'accusative': ['качество структуры материала']}},\n",
       " {'DANGER': {'definition': 'Предостережение об опасности или возможной ошибке',\n",
       "   'examples': ['проблема', 'взлом', 'ловушка'],\n",
       "   'accusative': ['ошибки или опасности, с которыми может столкнуться читатель']}},\n",
       " {'PART': {'definition': 'Указание части длинного повествования. Указание части в заголовке подсказывает: перед нами часть большого текста. Хорошо работает следующий формат: Общее название группы технологий. Часть N. Название технологии.',\n",
       "   'examples': ['часть 1/3', 'глава вторая'],\n",
       "   'accusative': ['если это статья из нескольких частей, то какая это часть']}},\n",
       " {'TODO': {'definition': 'Побуждение к действию или само действие',\n",
       "   'examples': ['пишем программу', 'настройка и ремонт', 'извлекаем золото'],\n",
       "   'accusative': ['действие, которое совершит пользователь',\n",
       "    'действие, совершаемое пользователем']}},\n",
       " {'EMO': {'definition': 'Эмоция.  С эмоциями не стоит перебарщивать, но иногда сильная эмоция или выражение отношения — то, что нужно.',\n",
       "   'examples': ['чертовски тяжело', 'худшее, что могло случиться с'],\n",
       "   'accusative': ['эмоцию (если она уместна)']}},\n",
       " {'ADV': {'definition': 'Преимущество, получаемое читателем',\n",
       "   'examples': ['бесплатно', 'своими руками', 'в домашних условиях'],\n",
       "   'accusative': ['преимущества, которые получит пользователь получит от прочтения']}},\n",
       " {'LANG': {'definition': '',\n",
       "   'examples': ['Python', 'Java', 'C++'],\n",
       "   'accusative': ['язык программирования']}},\n",
       " {'TECH': {'definition': 'Технический термин из мира IT',\n",
       "   'examples': ['HTTP/2.0', 'десериализация', 'изоляция транзакций'],\n",
       "   'accusative': ['технические детали']}},\n",
       " {'OS': {'definition': 'Операционная система',\n",
       "   'examples': ['Windows', 'Mac OS', 'Android', 'Linux'],\n",
       "   'accusative': ['операционную систему']}},\n",
       " {'PROGRAM': {'definition': 'Программное обеспечение',\n",
       "   'examples': ['Sublime Text', 'Visual Studio'],\n",
       "   'accusative': ['использовавшуюся программу']}},\n",
       " {'DEVICE': {'definition': 'Устройство',\n",
       "   'examples': ['смартфон', 'Raspberry Pi'],\n",
       "   'accusative': ['техническое устройство']}},\n",
       " {'SITE': {'definition': 'Cайт',\n",
       "   'examples': ['Хабр', 'proglib.io'],\n",
       "   'accusative': ['веб-сайт']}},\n",
       " {'ANNOUNCE': {'definition': 'Анонс события',\n",
       "   'examples': ['мартовский релиз', 'запустит'],\n",
       "   'accusative': ['анонс события']}},\n",
       " {'MATH': {'definition': 'Термин из математики, статистики',\n",
       "   'examples': ['простое число', 'градиентный спуск'],\n",
       "   'accusative': ['математические тонкости']}},\n",
       " {'GAME': {'definition': '',\n",
       "   'examples': ['Mortal Kombat', 'GTA'],\n",
       "   'accusative': ['название игры (если это вдруг уместно)']}},\n",
       " {'NEWS': {'definition': 'Новость. Обычно новости из мира IT актуальные совсем недолгое время',\n",
       "   'examples': ['состоялся', 'удостоен', 'опубликовала'],\n",
       "   'accusative': ['какой-то новостной аспект (если речь о новости)']}},\n",
       " {'CONF': {'definition': 'Название конференции',\n",
       "   'examples': ['Игромир', 'Moscow Python'],\n",
       "   'accusative': ['название конференции (если речь идет о конференции)']}},\n",
       " {'COND': {'definition': 'Особые условия, при которых актуален материал публикации',\n",
       "   'examples': ['при удаленной работе',\n",
       "    'под высокой нагрузкой',\n",
       "    'работая за компьютером'],\n",
       "   'accusative': ['особые условия, при которых актуален материал публикации']}},\n",
       " {'APP': {'definition': 'Популярное приложение',\n",
       "   'examples': ['TikTok', 'Instagram'],\n",
       "   'accusative': ['приложение']}},\n",
       " {'VERSION': {'definition': 'Версия языка, программы, библиотеки',\n",
       "   'examples': ['3.6+', '2.1.4'],\n",
       "   'accusative': ['версию языка, программы, библиотеки']}},\n",
       " {'LIB': {'definition': 'Библиотека для разработки ПО',\n",
       "   'examples': ['React', 'jQuery', 'asyncio'],\n",
       "   'accusative': ['применявшиеся библиотеки', 'библиотеку']}},\n",
       " {'FRAME': {'definition': 'Фреймворк для разработки ПО',\n",
       "   'examples': ['Django', 'Vue'],\n",
       "   'accusative': ['фреймворк', 'использовавшийся фреймворк']}}]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'{DATASETS_PATH}/tags.json') as f:\n",
    "    tags = json.load(f)\n",
    "    \n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
