{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель оценки заголовка\n",
    "\n",
    "Введенные или сгенерированные заголовки нужно как-то оценивать. Так как главной целью обычно является увеличение количества просмотров, то в качестве критерия можно использовать число просмотров у ранее опубликованных статей.\n",
    "\n",
    "Таким образом, перед нами стоит задача регрессии: на входе заголовок, на выходе число (балл от 0 до 10 с точностью 0.1).\n",
    "\n",
    "В качестве библиотеки, реализующей модель русского языка, мы используем spaCy (в первую очередь из соображений скорости)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка датасета\n",
    "\n",
    "В нашем распоряжении множество данных, полученных в результате парсинга. Объединим их в один большой датасет для построения модели оценки заголовков. Для его построения нам нужны те датасеты (сайты), для которых имеется информация о количестве просмотров статьи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import pickle\n",
    "\n",
    "# data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# data processing progress bar\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка естественного языка\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# библиотеки для машинного и глубокого обучения\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пути к датасетам\n",
    "DATASETS_PATH = \"/home/leo/DATASETS\"\n",
    "TOKENIZED_TITLES_PATH = f\"{DATASETS_PATH}/tokenized_titles.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь с источником данных и их характеристиками\n",
    "with open('../sources.pickle', 'rb') as f:\n",
    "    sources = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация большого числа заголовков — затратная по времени операция.\n",
    "# Поэтому предварительно токенизированные заголовки хранятся в виде\n",
    "# сжатого датафрайма\n",
    "tokenized_titles = pd.read_pickle(TOKENIZED_TITLES_PATH, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_titles.to_pickle(path=TOKENIZED_TITLES_PATH, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/.local/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# соединяем датасеты в один общий датасет с именем df\n",
    "dfs = dict()\n",
    "\n",
    "for source in sources:\n",
    "    dfs[source] = pd.read_csv(f\"{DATASETS_PATH}/{source}.csv\",\n",
    "                              index_col=0,\n",
    "                              parse_dates=['post_time', 'parse_time'])\n",
    "    dfs[source]['source'] = source\n",
    "    \n",
    "df = pd.concat(dfs[key] for key in dfs)\n",
    "\n",
    "# удаляем дубликаты\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# преобразуем количество просмотров к текстовому значению\n",
    "df.views_num = df.views_num.apply(lambda x: int(''.join(filter(str.isdigit, str(x)))))\n",
    "\n",
    "# приводим число просмотров к нормированной логарифмической шкале\n",
    "df.views_num = np.log(df.views_num)/np.log(df.views_num.max())\n",
    "\n",
    "# удаляем записи без просмотров (обычно это закрытые и недоступные статьи)\n",
    "df = df.drop(df[df.views_num == np.NINF].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединим датасет с токенизированные заголовки\n",
    "df = pd.concat([df, tokenized_titles], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Преобразование данных к векторному представлению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В качестве конечных данных нам нужны лишь сведения\n",
    "# о токенах заголовков и количестве просмотров статей.\n",
    "Xy = df[['doc', 'views_num']]\n",
    "\n",
    "# удаляем пропущенные значения, если таковые есть\n",
    "Xy = Xy.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Построение базовой модели\n",
    "\n",
    "Начнем с базовой модели: сопоставим каждому заголовку векторное представление, обучим модель для оценки заголовков и проверим качество скользящим контролем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.doc.apply(lambda x: x.vector)\n",
    "X = np.stack(X.values)\n",
    "y = Xy.views_num.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(verbose=1000,\n",
    "                          task_type=\"GPU\",\n",
    "                          devices='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.085254\n",
      "0:\tlearn: 0.1097669\ttotal: 21.2ms\tremaining: 21.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 1032.1875 Total: 2002.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999:\tlearn: 0.1037218\ttotal: 18.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f240beb6910>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/keras/regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,277\n",
      "Trainable params: 1,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=96, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3080/3080 [==============================] - 3s 810us/step - loss: 0.0213 - mse: 0.0213 - mae: 0.1089 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0859\n",
      "Epoch 2/150\n",
      "3080/3080 [==============================] - 3s 830us/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0858 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0851\n",
      "Epoch 3/150\n",
      "3080/3080 [==============================] - 3s 824us/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0848 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0851\n",
      "Epoch 4/150\n",
      "3080/3080 [==============================] - 2s 790us/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0843 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0844\n",
      "Epoch 5/150\n",
      "3080/3080 [==============================] - 2s 769us/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0845 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0847\n",
      "Epoch 6/150\n",
      "3080/3080 [==============================] - 2s 707us/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0842 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0846\n",
      "Epoch 7/150\n",
      "3080/3080 [==============================] - 2s 707us/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0843 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0844\n",
      "Epoch 8/150\n",
      "3080/3080 [==============================] - 2s 773us/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0841 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0843\n",
      "Epoch 9/150\n",
      "3080/3080 [==============================] - 2s 695us/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0840 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0843\n",
      "Epoch 10/150\n",
      "3080/3080 [==============================] - 2s 729us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0837 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0848\n",
      "Epoch 11/150\n",
      "3080/3080 [==============================] - 2s 750us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0837 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0842\n",
      "Epoch 12/150\n",
      "3080/3080 [==============================] - 2s 699us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0837 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0840\n",
      "Epoch 13/150\n",
      "3080/3080 [==============================] - 2s 771us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0833 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0841\n",
      "Epoch 14/150\n",
      "3080/3080 [==============================] - 2s 754us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0837 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0844\n",
      "Epoch 15/150\n",
      "3080/3080 [==============================] - 2s 805us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0833 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0842\n",
      "Epoch 16/150\n",
      "3080/3080 [==============================] - 2s 719us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0831 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0840\n",
      "Epoch 17/150\n",
      "3080/3080 [==============================] - 3s 914us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0835 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0848\n",
      "Epoch 18/150\n",
      "3080/3080 [==============================] - 2s 811us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0834 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0838\n",
      "Epoch 19/150\n",
      "3080/3080 [==============================] - 3s 865us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0832 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0840\n",
      "Epoch 20/150\n",
      "3080/3080 [==============================] - 3s 966us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0833 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0844\n",
      "Epoch 21/150\n",
      "3080/3080 [==============================] - 3s 882us/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0834 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0839\n",
      "Epoch 22/150\n",
      "3080/3080 [==============================] - 3s 823us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0831 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0838\n",
      "Epoch 23/150\n",
      "3080/3080 [==============================] - 3s 819us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0830 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0840\n",
      "Epoch 24/150\n",
      "3080/3080 [==============================] - 2s 809us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0832 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0843\n",
      "Epoch 25/150\n",
      "3080/3080 [==============================] - 3s 823us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 26/150\n",
      "3080/3080 [==============================] - 3s 981us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0828 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0849\n",
      "Epoch 27/150\n",
      "3080/3080 [==============================] - 3s 932us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0841\n",
      "Epoch 28/150\n",
      "3080/3080 [==============================] - 3s 926us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0829 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0845\n",
      "Epoch 29/150\n",
      "3080/3080 [==============================] - 3s 943us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0830 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0848\n",
      "Epoch 30/150\n",
      "3080/3080 [==============================] - 3s 813us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0830 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0843\n",
      "Epoch 31/150\n",
      "3080/3080 [==============================] - 3s 844us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0829 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0842\n",
      "Epoch 32/150\n",
      "3080/3080 [==============================] - 2s 793us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0829 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 33/150\n",
      "3080/3080 [==============================] - 3s 821us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0833 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0836\n",
      "Epoch 34/150\n",
      "3080/3080 [==============================] - 3s 823us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0835\n",
      "Epoch 35/150\n",
      "3080/3080 [==============================] - 2s 778us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 36/150\n",
      "3080/3080 [==============================] - 3s 904us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0829 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0848\n",
      "Epoch 37/150\n",
      "3080/3080 [==============================] - 3s 844us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0832 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0839\n",
      "Epoch 38/150\n",
      "3080/3080 [==============================] - 3s 850us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0836\n",
      "Epoch 39/150\n",
      "3080/3080 [==============================] - 2s 800us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 40/150\n",
      "3080/3080 [==============================] - 2s 777us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0836\n",
      "Epoch 41/150\n",
      "3080/3080 [==============================] - 2s 776us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 42/150\n",
      "3080/3080 [==============================] - 2s 800us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 43/150\n",
      "3080/3080 [==============================] - 3s 890us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 44/150\n",
      "3080/3080 [==============================] - 3s 834us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 45/150\n",
      "3080/3080 [==============================] - 3s 830us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 46/150\n",
      "3080/3080 [==============================] - 3s 853us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0840\n",
      "Epoch 47/150\n",
      "3080/3080 [==============================] - 3s 935us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0839\n",
      "Epoch 48/150\n",
      "3080/3080 [==============================] - 3s 984us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 49/150\n",
      "3080/3080 [==============================] - 2s 807us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0835\n",
      "Epoch 50/150\n",
      "3080/3080 [==============================] - 2s 808us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0834\n",
      "Epoch 51/150\n",
      "3080/3080 [==============================] - 2s 800us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 52/150\n",
      "3080/3080 [==============================] - 2s 807us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0835\n",
      "Epoch 53/150\n",
      "3080/3080 [==============================] - 3s 826us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0835\n",
      "Epoch 54/150\n",
      "3080/3080 [==============================] - 3s 820us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0834\n",
      "Epoch 55/150\n",
      "3080/3080 [==============================] - 3s 847us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 56/150\n",
      "3080/3080 [==============================] - 3s 942us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 57/150\n",
      "3080/3080 [==============================] - 3s 965us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0834\n",
      "Epoch 58/150\n",
      "3080/3080 [==============================] - 3s 969us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0834\n",
      "Epoch 59/150\n",
      "3080/3080 [==============================] - 3s 840us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0828 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 60/150\n",
      "3080/3080 [==============================] - 2s 790us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 61/150\n",
      "3080/3080 [==============================] - 3s 814us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0841\n",
      "Epoch 62/150\n",
      "3080/3080 [==============================] - 2s 804us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0834\n",
      "Epoch 63/150\n",
      "3080/3080 [==============================] - 3s 852us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0839\n",
      "Epoch 64/150\n",
      "3080/3080 [==============================] - 3s 848us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 65/150\n",
      "3080/3080 [==============================] - 3s 849us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0841\n",
      "Epoch 66/150\n",
      "3080/3080 [==============================] - 3s 855us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0841\n",
      "Epoch 67/150\n",
      "3080/3080 [==============================] - 3s 845us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 68/150\n",
      "3080/3080 [==============================] - 3s 977us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0824 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0848\n",
      "Epoch 69/150\n",
      "3080/3080 [==============================] - 3s 877us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0844\n",
      "Epoch 70/150\n",
      "3080/3080 [==============================] - 3s 911us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0840\n",
      "Epoch 71/150\n",
      "3080/3080 [==============================] - 3s 819us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 72/150\n",
      "3080/3080 [==============================] - 3s 863us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 73/150\n",
      "3080/3080 [==============================] - 3s 919us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0840\n",
      "Epoch 74/150\n",
      "3080/3080 [==============================] - 3s 821us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 75/150\n",
      "3080/3080 [==============================] - 3s 822us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0840\n",
      "Epoch 76/150\n",
      "3080/3080 [==============================] - 3s 844us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0844\n",
      "Epoch 77/150\n",
      "3080/3080 [==============================] - 3s 862us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 78/150\n",
      "3080/3080 [==============================] - 3s 852us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 79/150\n",
      "3080/3080 [==============================] - 3s 846us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 80/150\n",
      "3080/3080 [==============================] - 3s 826us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0838\n",
      "Epoch 81/150\n",
      "3080/3080 [==============================] - 3s 819us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 82/150\n",
      "3080/3080 [==============================] - 3s 840us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0842\n",
      "Epoch 83/150\n",
      "3080/3080 [==============================] - 3s 843us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0835\n",
      "Epoch 84/150\n",
      "3080/3080 [==============================] - 3s 832us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0836\n",
      "Epoch 85/150\n",
      "3080/3080 [==============================] - 3s 904us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0835\n",
      "Epoch 86/150\n",
      "3080/3080 [==============================] - 3s 959us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 87/150\n",
      "3080/3080 [==============================] - 3s 832us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 88/150\n",
      "3080/3080 [==============================] - 3s 902us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0834\n",
      "Epoch 89/150\n",
      "3080/3080 [==============================] - 3s 856us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0833\n",
      "Epoch 90/150\n",
      "3080/3080 [==============================] - 3s 826us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0838\n",
      "Epoch 91/150\n",
      "3080/3080 [==============================] - 3s 902us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0837\n",
      "Epoch 92/150\n",
      "3080/3080 [==============================] - 3s 1ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0836\n",
      "Epoch 93/150\n",
      "3080/3080 [==============================] - 3s 970us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0834\n",
      "Epoch 94/150\n",
      "3080/3080 [==============================] - 3s 921us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 95/150\n",
      "3080/3080 [==============================] - 3s 841us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0835\n",
      "Epoch 96/150\n",
      "3080/3080 [==============================] - 3s 853us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0840\n",
      "Epoch 97/150\n",
      "3080/3080 [==============================] - 3s 951us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0834\n",
      "Epoch 98/150\n",
      "3080/3080 [==============================] - 3s 879us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0835\n",
      "Epoch 99/150\n",
      "3080/3080 [==============================] - 3s 934us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 100/150\n",
      "3080/3080 [==============================] - 3s 1ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0841\n",
      "Epoch 101/150\n",
      "3080/3080 [==============================] - 3s 824us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0848\n",
      "Epoch 102/150\n",
      "3080/3080 [==============================] - 3s 823us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0839\n",
      "Epoch 103/150\n",
      "3080/3080 [==============================] - 3s 835us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0835\n",
      "Epoch 104/150\n",
      "3080/3080 [==============================] - 3s 849us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 105/150\n",
      "3080/3080 [==============================] - 3s 937us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0833\n",
      "Epoch 106/150\n",
      "3080/3080 [==============================] - 3s 859us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0840\n",
      "Epoch 107/150\n",
      "3080/3080 [==============================] - 3s 867us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0833\n",
      "Epoch 108/150\n",
      "3080/3080 [==============================] - 3s 954us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0819 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0851\n",
      "Epoch 109/150\n",
      "3080/3080 [==============================] - 3s 914us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 110/150\n",
      "3080/3080 [==============================] - 3s 840us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0839\n",
      "Epoch 111/150\n",
      "3080/3080 [==============================] - 3s 847us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 112/150\n",
      "3080/3080 [==============================] - 3s 829us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0834\n",
      "Epoch 113/150\n",
      "3080/3080 [==============================] - 3s 904us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0835\n",
      "Epoch 114/150\n",
      "3080/3080 [==============================] - 2s 804us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0819 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0833\n",
      "Epoch 115/150\n",
      "3080/3080 [==============================] - 2s 797us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 116/150\n",
      "3080/3080 [==============================] - 3s 990us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0839\n",
      "Epoch 117/150\n",
      "3080/3080 [==============================] - 3s 830us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0824 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0835\n",
      "Epoch 118/150\n",
      "3080/3080 [==============================] - 2s 765us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0820 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 119/150\n",
      "3080/3080 [==============================] - 2s 749us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0820 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0835\n",
      "Epoch 120/150\n",
      "3080/3080 [==============================] - 2s 751us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0834\n",
      "Epoch 121/150\n",
      "3080/3080 [==============================] - 2s 766us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0839\n",
      "Epoch 122/150\n",
      "3080/3080 [==============================] - 3s 988us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0826 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 123/150\n",
      "3080/3080 [==============================] - 2s 784us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0820 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 124/150\n",
      "3080/3080 [==============================] - 2s 739us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0841\n",
      "Epoch 125/150\n",
      "3080/3080 [==============================] - 2s 761us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0847\n",
      "Epoch 126/150\n",
      "3080/3080 [==============================] - 2s 761us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 127/150\n",
      "3080/3080 [==============================] - 2s 776us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0834\n",
      "Epoch 128/150\n",
      "3080/3080 [==============================] - 2s 765us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0839\n",
      "Epoch 129/150\n",
      "3080/3080 [==============================] - 2s 750us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0835\n",
      "Epoch 130/150\n",
      "3080/3080 [==============================] - 2s 749us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 131/150\n",
      "3080/3080 [==============================] - 2s 807us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0847\n",
      "Epoch 132/150\n",
      "3080/3080 [==============================] - 3s 820us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 133/150\n",
      "3080/3080 [==============================] - 2s 782us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0833\n",
      "Epoch 134/150\n",
      "3080/3080 [==============================] - 2s 783us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0834\n",
      "Epoch 135/150\n",
      "3080/3080 [==============================] - 2s 799us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0820 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0835\n",
      "Epoch 136/150\n",
      "3080/3080 [==============================] - 2s 725us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 137/150\n",
      "3080/3080 [==============================] - 2s 793us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0841\n",
      "Epoch 138/150\n",
      "3080/3080 [==============================] - 2s 780us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0835\n",
      "Epoch 139/150\n",
      "3080/3080 [==============================] - 3s 852us/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0816 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 140/150\n",
      "3080/3080 [==============================] - 3s 929us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0835\n",
      "Epoch 141/150\n",
      "3080/3080 [==============================] - 3s 904us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0842\n",
      "Epoch 142/150\n",
      "3080/3080 [==============================] - 3s 984us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0824 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0841\n",
      "Epoch 143/150\n",
      "3080/3080 [==============================] - 3s 923us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0843\n",
      "Epoch 144/150\n",
      "3080/3080 [==============================] - 3s 855us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0820 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 145/150\n",
      "3080/3080 [==============================] - 3s 864us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0823 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0837\n",
      "Epoch 146/150\n",
      "3080/3080 [==============================] - 3s 860us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0825 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0833\n",
      "Epoch 147/150\n",
      "3080/3080 [==============================] - 2s 805us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0822 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0835\n",
      "Epoch 148/150\n",
      "3080/3080 [==============================] - 2s 791us/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0820 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 149/150\n",
      "3080/3080 [==============================] - 3s 815us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0840\n",
      "Epoch 150/150\n",
      "3080/3080 [==============================] - 2s 792us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0821 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0842\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=150,\n",
    "                    batch_size=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-dc88a5488631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascienceplus.com/keras-regression-based-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Проверка дополнительных гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация дополнительных признаков\n",
    "# Xy.loc[:, ['title']] = Xy.title.apply(str)\n",
    "\n",
    "# Xy.loc[:, ['doc']] = Xy.title.progress_apply(nlp)\n",
    "\n",
    "# длина заголовка в символах\n",
    "# Xy.loc[:, ['len']] = Xy.title.apply(len)\n",
    "\n",
    "# количество токенов\n",
    "# Xy.loc[:, ['tokens_num']] = Xy.tokens.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.from_numpy(y_train.values).float().to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
