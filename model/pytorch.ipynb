{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель оценки заголовка\n",
    "\n",
    "Введенные или сгенерированные заголовки нужно как-то оценивать. Так как главной целью обычно является увеличение количества просмотров, то в качестве критерия нужно использовать число просмотров у ранее опубликованных статей. То есть перед нами стоит задача **регрессии**: на входе заголовок, на выходе число (балл от 0.0 до 10.0 с точностью 0.1).\n",
    "\n",
    "Для работы с текстами мы используем библиотеку [transformers](https://huggingface.co/transformers/), обладающую высокой эффективностью для задач распознавания особенностей текста (NLU) и его генерации (NLG). Библиотека предоставляет удобный интерфейс для работы с предобученными NLP-моделями на основе архитектуры transformer. Факти это pytorch-модели для NLP-задач, которые легко переводить в tensorflow-модели и обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# standard libraries\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "# data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# make numpy printouts easier to read\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# data processing progress bar\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model_name = 'DeepPavlov/rubert-base-cased'\n",
    "\n",
    "# пути к датасетам\n",
    "DATASETS_PATH = \"/home/leo/DATASETS\"\n",
    "# TOKENIZED_TITLES_PATH = f\"{DATASETS_PATH}/tokenized_titles.pickle\"\n",
    "\n",
    "# общий для приложений словарь с источником данных и их характеристиками\n",
    "with open('../sources.pickle', 'rb') as f:\n",
    "    sources = pickle.load(f)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных\n",
    "## 1.1. Соединение датафреймов\n",
    "\n",
    "В нашем распоряжении имеется множество данных, полученных в результате парсинга. Объединим их в один большой датасет для построения модели оценки заголовков. Для построения будем использовать те датасеты (сайты), которые содержат информацию о количестве просмотров статей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post_time</th>\n",
       "      <th>short_text</th>\n",
       "      <th>views_num</th>\n",
       "      <th>parse_time</th>\n",
       "      <th>filename</th>\n",
       "      <th>source</th>\n",
       "      <th>likes_num</th>\n",
       "      <th>favs_num</th>\n",
       "      <th>comments_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://tproger.ru/articles/kak-bystro-razvernut-hranilishhe-i-analitiku-dannyh-dlja-biznesa/</th>\n",
       "      <td>Как быстро развернуть хранилище и аналитику да...</td>\n",
       "      <td>2021-03-01 12:32:23+03:00</td>\n",
       "      <td>Сегодня хочу рассказать историю проекта по зап...</td>\n",
       "      <td>7825</td>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>59a7ab25-11f7-502a-b63a-bbdcb121f488</td>\n",
       "      <td>tproger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://tproger.ru/articles/7-prakticheskih-zadanij-s-sobesedovanija-na-poziciju-junior-java-developer/</th>\n",
       "      <td>7 практических заданий с собеседования на пози...</td>\n",
       "      <td>2021-03-01 09:05:11+03:00</td>\n",
       "      <td>Для начинающего разработчика очень важно не то...</td>\n",
       "      <td>6741</td>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>80f10716-5243-55ca-a67d-4dfe77cd27a5</td>\n",
       "      <td>tproger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://tproger.ru/quiz/test-chto-mozhet-jeta-nejroset/</th>\n",
       "      <td>Тест: что реально, а что создала нейросеть?</td>\n",
       "      <td>2021-02-26 19:39:50+03:00</td>\n",
       "      <td>Сегодня нейронные сети используются в сельском...</td>\n",
       "      <td>4032</td>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>aaffd2c5-592f-5d7b-b972-95073d0da49a</td>\n",
       "      <td>tproger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://tproger.ru/articles/kak-najti-dejstvitelno-horoshij-kurs-po-razrabotke-8-shagov-na-puti-k-pravilnomu-vyboru/</th>\n",
       "      <td>Как найти действительно хороший курс по разраб...</td>\n",
       "      <td>2021-02-26 17:29:00+03:00</td>\n",
       "      <td>Сразу хочется пошутить и предложить разработат...</td>\n",
       "      <td>1121</td>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>16f80dbb-8e7c-5a5b-9025-b2fdef30bfd0</td>\n",
       "      <td>tproger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://tproger.ru/articles/blackbox-skanery-v-processe-ocenki-bezopasnosti-prilozhenija/</th>\n",
       "      <td>Blackbox-сканеры в процессе оценки безопасност...</td>\n",
       "      <td>2021-02-26 15:16:46+03:00</td>\n",
       "      <td>Профиль задач quality engineer (QE) достаточно...</td>\n",
       "      <td>187</td>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>9d58bde6-7aaf-57a4-b381-25171b9a368f</td>\n",
       "      <td>tproger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                title  \\\n",
       "https://tproger.ru/articles/kak-bystro-razvernu...  Как быстро развернуть хранилище и аналитику да...   \n",
       "https://tproger.ru/articles/7-prakticheskih-zad...  7 практических заданий с собеседования на пози...   \n",
       "https://tproger.ru/quiz/test-chto-mozhet-jeta-n...        Тест: что реально, а что создала нейросеть?   \n",
       "https://tproger.ru/articles/kak-najti-dejstvite...  Как найти действительно хороший курс по разраб...   \n",
       "https://tproger.ru/articles/blackbox-skanery-v-...  Blackbox-сканеры в процессе оценки безопасност...   \n",
       "\n",
       "                                                                    post_time  \\\n",
       "https://tproger.ru/articles/kak-bystro-razvernu...  2021-03-01 12:32:23+03:00   \n",
       "https://tproger.ru/articles/7-prakticheskih-zad...  2021-03-01 09:05:11+03:00   \n",
       "https://tproger.ru/quiz/test-chto-mozhet-jeta-n...  2021-02-26 19:39:50+03:00   \n",
       "https://tproger.ru/articles/kak-najti-dejstvite...  2021-02-26 17:29:00+03:00   \n",
       "https://tproger.ru/articles/blackbox-skanery-v-...  2021-02-26 15:16:46+03:00   \n",
       "\n",
       "                                                                                           short_text  \\\n",
       "https://tproger.ru/articles/kak-bystro-razvernu...  Сегодня хочу рассказать историю проекта по зап...   \n",
       "https://tproger.ru/articles/7-prakticheskih-zad...  Для начинающего разработчика очень важно не то...   \n",
       "https://tproger.ru/quiz/test-chto-mozhet-jeta-n...  Сегодня нейронные сети используются в сельском...   \n",
       "https://tproger.ru/articles/kak-najti-dejstvite...  Сразу хочется пошутить и предложить разработат...   \n",
       "https://tproger.ru/articles/blackbox-skanery-v-...  Профиль задач quality engineer (QE) достаточно...   \n",
       "\n",
       "                                                    views_num parse_time  \\\n",
       "https://tproger.ru/articles/kak-bystro-razvernu...       7825 2021-03-14   \n",
       "https://tproger.ru/articles/7-prakticheskih-zad...       6741 2021-03-14   \n",
       "https://tproger.ru/quiz/test-chto-mozhet-jeta-n...       4032 2021-03-14   \n",
       "https://tproger.ru/articles/kak-najti-dejstvite...       1121 2021-03-14   \n",
       "https://tproger.ru/articles/blackbox-skanery-v-...        187 2021-03-14   \n",
       "\n",
       "                                                                                filename  \\\n",
       "https://tproger.ru/articles/kak-bystro-razvernu...  59a7ab25-11f7-502a-b63a-bbdcb121f488   \n",
       "https://tproger.ru/articles/7-prakticheskih-zad...  80f10716-5243-55ca-a67d-4dfe77cd27a5   \n",
       "https://tproger.ru/quiz/test-chto-mozhet-jeta-n...  aaffd2c5-592f-5d7b-b972-95073d0da49a   \n",
       "https://tproger.ru/articles/kak-najti-dejstvite...  16f80dbb-8e7c-5a5b-9025-b2fdef30bfd0   \n",
       "https://tproger.ru/articles/blackbox-skanery-v-...  9d58bde6-7aaf-57a4-b381-25171b9a368f   \n",
       "\n",
       "                                                     source  likes_num  \\\n",
       "https://tproger.ru/articles/kak-bystro-razvernu...  tproger        NaN   \n",
       "https://tproger.ru/articles/7-prakticheskih-zad...  tproger        NaN   \n",
       "https://tproger.ru/quiz/test-chto-mozhet-jeta-n...  tproger        NaN   \n",
       "https://tproger.ru/articles/kak-najti-dejstvite...  tproger        NaN   \n",
       "https://tproger.ru/articles/blackbox-skanery-v-...  tproger        NaN   \n",
       "\n",
       "                                                    favs_num  comments_num  \n",
       "https://tproger.ru/articles/kak-bystro-razvernu...       NaN           NaN  \n",
       "https://tproger.ru/articles/7-prakticheskih-zad...       NaN           NaN  \n",
       "https://tproger.ru/quiz/test-chto-mozhet-jeta-n...       NaN           NaN  \n",
       "https://tproger.ru/articles/kak-najti-dejstvite...       NaN           NaN  \n",
       "https://tproger.ru/articles/blackbox-skanery-v-...       NaN           NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# соединяем датасеты в один общий датасет с именем df\n",
    "dfs = dict()\n",
    "\n",
    "for source in sources:\n",
    "    dfs[source] = pd.read_csv(f\"{DATASETS_PATH}/{source}.csv\",\n",
    "                              index_col=0,\n",
    "                              parse_dates=['post_time', 'parse_time'])\n",
    "    dfs[source]['source'] = source\n",
    "    \n",
    "df = pd.concat(dfs[key] for key in dfs)\n",
    "\n",
    "# преобразуем количество просмотров\n",
    "df.views_num = df.views_num.apply(lambda x: int(''.join(filter(str.isdigit, str(x)))))\n",
    "\n",
    "# удаляем закрытые и недоступные статьи\n",
    "df = df.drop(df[df.views_num == 0.0].index)\n",
    "\n",
    "# удаляем дубликаты\n",
    "df = df.drop_duplicates()\n",
    "df = df.loc[~df.index.duplicated(keep='last')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Коррекция случаев заниженного числа просмотров\n",
    "Число просмотров на сайтах иногда существуенно отстает от предполагаемого или не всегда корректно рассчитано. Особенно это заметно на когда количество просмотров меньше числа лайков и добавлений в избранные статьи. Чтобы скорректировать такие значения, построим простую  регрессионную SGD-модель на данных, внушающих доверие и экстраполируем результат на «подозрительные» данные о числе просмотров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['post_time'] = pd.to_datetime(df['post_time'], utc=True)\n",
    "df['mln_secs_to_now'] = (pd.Timestamp.now(tz='UTC') - df['post_time']).apply(lambda x: x.total_seconds())*1e-6\n",
    "df_tmp = df[['likes_num', 'favs_num', 'comments_num', 'views_num']].dropna()\n",
    "df_tmp['suspicious'] = [False]*df_tmp.shape[0]\n",
    "for col in ('likes', 'favs', 'comments'):\n",
    "    df_tmp['suspicious'] += df_tmp[f'{col}_num'] > 0.1*df_tmp['views_num']\n",
    "\n",
    "df_tmp_susp = df_tmp[df_tmp['suspicious'] == True]\n",
    "df_tmp = df_tmp[df_tmp['suspicious'] == False]\n",
    "df_tmp = df_tmp.drop(columns=['suspicious'])\n",
    "df_tmp_susp = df_tmp_susp.drop(columns=['suspicious'])\n",
    "\n",
    "y = df_tmp['views_num']\n",
    "X = df_tmp.drop(columns=['views_num'])\n",
    "reg = make_pipeline(StandardScaler(),\n",
    "                    RandomForestRegressor(n_jobs=20))\n",
    "reg.fit(X, y)\n",
    "df_tmp_susp['views_num'] = reg.predict(df_tmp_susp.drop(columns=['views_num']))\n",
    "df_tmp_susp['views_num'] = df_tmp_susp['views_num'].apply(round)\n",
    "df_tmp = pd.concat([df_tmp, df_tmp_susp])\n",
    "df.update(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Преобразование целевой переменной: от числа просмотров к рейтингу\n",
    "Оставим только данные, которые используются для построения модели: текст заголовка (`X`) и число просмотров (`y`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = df[['title', 'views_num']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортируем статьи по количеству просмотров и зададим для каждой позиции рейтинг `score`, равномерно распределенный между 0 для непросматриваемой статьи и 10 для самой просматриваемой. Таким образом, оценка в 9.0 означает, что подобные заголовки имели не меньшее число просмотров, чем 90% иследованного набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.sort_values(by='views_num', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy['score'] = np.linspace(0, 1, Xy.shape[0])\n",
    "X, y = Xy.title, Xy.score\n",
    "del Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-501ac0069a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Xy' is not defined"
     ]
    }
   ],
   "source": [
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes_num</th>\n",
       "      <th>favs_num</th>\n",
       "      <th>comments_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/30662</th>\n",
       "      <td>2.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/336572</th>\n",
       "      <td>13.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/370295</th>\n",
       "      <td>19.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/363933</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/311664</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/76471</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/204454</th>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/84206</th>\n",
       "      <td>53.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/407341</th>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habr.com/ru/post/21464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 likes_num  favs_num  comments_num\n",
       "https://habr.com/ru/post/30662         2.0     147.0          93.0\n",
       "https://habr.com/ru/post/336572       13.0      69.0          55.0\n",
       "https://habr.com/ru/post/370295       19.0     161.0          89.0\n",
       "https://habr.com/ru/post/363933        5.0      17.0          20.0\n",
       "https://habr.com/ru/post/311664        0.0       8.0           3.0\n",
       "...                                    ...       ...           ...\n",
       "https://habr.com/ru/post/76471         4.0       2.0           8.0\n",
       "https://habr.com/ru/post/204454        6.0      30.0           7.0\n",
       "https://habr.com/ru/post/84206        53.0      57.0          90.0\n",
       "https://habr.com/ru/post/407341       16.0      25.0          26.0\n",
       "https://habr.com/ru/post/21464         0.0       0.0           9.0\n",
       "\n",
       "[170572 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Построение модели на базе transformers\n",
    "\n",
    "Начнем с базовой модели: сопоставим каждому заголовку векторное представление и обучим модель для оценки заголовков. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = Xy.title.apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# в библиотеке transformers таск sentiment-analysis\n",
    "# соответствует TextClassificationPipeline\n",
    "# classifier = pipeline(task=\"sentiment-analysis\",\n",
    "#                       model=model,\n",
    "#                       tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens_in_title = Xy.doc.apply(len).max()\n",
    "cols_num = 96\n",
    "\n",
    "def make_stack(doc):\n",
    "    # представляем заголовок как набор векторов\n",
    "    words_stack = np.vstack(word.vector for word in doc)\n",
    "    \n",
    "    # дополняем плоскость нулями\n",
    "    zeros_rows_num = max_tokens_in_title-words_stack.shape[0]\n",
    "    zeros_stack = np.zeros((zeros_rows_num, cols_num))\n",
    "    plate_stack = np.vstack([words_stack, zeros_stack])\n",
    "    return plate_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.from_numpy(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Проверка дополнительных гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация дополнительных признаков\n",
    "# Xy.loc[:, ['title']] = Xy.title.apply(str)\n",
    "\n",
    "# Xy.loc[:, ['doc']] = Xy.title.progress_apply(nlp)\n",
    "\n",
    "# длина заголовка в символах\n",
    "# Xy.loc[:, ['len']] = Xy.title.apply(len)\n",
    "\n",
    "# количество токенов\n",
    "# Xy.loc[:, ['tokens_num']] = Xy.tokens.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XXX Archive & Drafts XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация большого числа заголовков — затратная по времени операция.\n",
    "# Поэтому предварительно токенизированные заголовки хранятся в виде\n",
    "# сжатого датафрайма\n",
    "#tokenized_titles = pd.read_pickle(TOKENIZED_TITLES_PATH, compression='gzip')\n",
    "\n",
    "# for i in [3, 8, 9]:\n",
    "#     spacy.displacy.render(tokenized_titles.iloc[i], style='ent', jupyter=True)\n",
    "\n",
    "# tokenized_titles.to_pickle(path=TOKENIZED_TITLES_PATH, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
