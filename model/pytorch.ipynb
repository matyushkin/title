{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель оценки заголовка\n",
    "\n",
    "Введенные или сгенерированные заголовки нужно как-то оценивать. Так как главной целью обычно является увеличение количества просмотров, то в качестве критерия можно использовать число просмотров у ранее опубликованных статей.\n",
    "\n",
    "Таким образом, перед нами стоит задача регрессии: на входе заголовок, на выходе число (балл от 0 до 10 с точностью 0.1).\n",
    "\n",
    "В качестве библиотеки, реализующей модель русского языка, мы используем spaCy (в первую очередь из соображений скорости)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка датасета\n",
    "\n",
    "В нашем распоряжении множество данных, полученных в результате парсинга. Объединим их в один большой датасет для построения модели оценки заголовков. Для его построения нам нужны те датасеты (сайты), для которых имеется информация о количестве просмотров статьи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стандартная библиотека\n",
    "import pickle\n",
    "\n",
    "# библиотеки для работы с данными\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# прогресс-бары\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка естественного языка\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пути к датасетам\n",
    "DATASETS_PATH = \"/home/leo/DATASETS\"\n",
    "TOKENIZED_TITLES_PATH = f\"{DATASETS_PATH}/tokenized_titles.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь с источником данных и их характеристиками\n",
    "with open('../sources.pickle', 'rb') as f:\n",
    "    sources = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация большого числа заголовков — затратная по времени операция.\n",
    "# Поэтому предварительно токенизированные заголовки хранятся в виде\n",
    "# сжатого датафрайма\n",
    "tokenized_titles = pd.read_pickle(TOKENIZED_TITLES_PATH, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_titles.to_pickle(path=TOKENIZED_TITLES_PATH, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/.local/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# соединяем датасеты в один общий датасет с именем df\n",
    "dfs = dict()\n",
    "\n",
    "for source in sources:\n",
    "    dfs[source] = pd.read_csv(f\"{DATASETS_PATH}/{source}.csv\",\n",
    "                              index_col=0,\n",
    "                              parse_dates=['post_time', 'parse_time'])\n",
    "    dfs[source]['source'] = source\n",
    "    \n",
    "df = pd.concat(dfs[key] for key in dfs)\n",
    "\n",
    "# удаляем дубликаты\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# преобразуем количество просмотров к текстовому значению\n",
    "df.views_num = df.views_num.apply(lambda x: int(''.join(filter(str.isdigit, str(x)))))\n",
    "\n",
    "# приводим число просмотров к нормированной логарифмической шкале\n",
    "df.views_num = np.log(df.views_num)/np.log(df.views_num.max())\n",
    "\n",
    "# удаляем записи без просмотров (обычно это закрытые и недоступные статьи)\n",
    "df = df.drop(df[df.views_num == np.NINF].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединим датасет с токенизированные заголовки\n",
    "df = pd.concat([df, tokenized_titles], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Преобразование данных к векторному представлению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В качестве конечных данных нам нужны лишь сведения\n",
    "# о токенах заголовков и количестве просмотров статей.\n",
    "Xy = df[['doc', 'views_num']]\n",
    "\n",
    "# удаляем пропущенные значения, если таковые есть\n",
    "Xy = Xy.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Построение базовой модели\n",
    "\n",
    "Начнем с базовой модели: сопоставим каждому заголовку векторное представление, обучим модель для оценки заголовков и проверим качество скользящим контролем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.doc.apply(lambda x: x.vector)\n",
    "X = np.stack(X.values)\n",
    "y = Xy.views_num.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(verbose=1000,\n",
    "                          task_type=\"GPU\",\n",
    "                          devices='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.085254\n",
      "0:\tlearn: 0.1097669\ttotal: 21.2ms\tremaining: 21.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 1032.1875 Total: 2002.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999:\tlearn: 0.1037218\ttotal: 18.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f240beb6910>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Проверка дополнительных гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация дополнительных признаков\n",
    "# Xy.loc[:, ['title']] = Xy.title.apply(str)\n",
    "\n",
    "# Xy.loc[:, ['doc']] = Xy.title.progress_apply(nlp)\n",
    "\n",
    "# длина заголовка в символах\n",
    "# Xy.loc[:, ['len']] = Xy.title.apply(len)\n",
    "\n",
    "# количество токенов\n",
    "# Xy.loc[:, ['tokens_num']] = Xy.tokens.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.from_numpy(y_train.values).float().to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
