{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCweGp9erSe_"
   },
   "source": [
    "# iTitle\n",
    "\n",
    "**Цель**: сделать веб-приложение, помогающее авторам и редакторам IT-публикаций подбирать к ним удачные заголовки.\n",
    "\n",
    "**Задача-минимум**: создать сервис, который учит автора использовать разумные подходы для составления говорящего заголовка. То есть такого заголовока, по которому читатель понимает, какую пользу он получит от прочтения статьи. Мы понимаем, что автору недостаточно оценки, с помощью сервиса он хотел бы получить конкретику, научиться распознавать индикаторы, по которым читатель выбирает статью. Эту проблему можно сформулировать в виде задачи распознавания именованных сущностей (англ. [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition), NER). Распознанные именованные сущности можно далее вмесе с токенизированным текстом использовать для выставления условного балла от 0 до 10, позволяющего автору быстро оценить и скорректировать результат.\n",
    "\n",
    "**Задача-максимум** (пока не решаем): генерация вариантов более качественных заголовков по тексту публикации или сочетанию чернового заголовка и краткого содержания.\n",
    "\n",
    "\n",
    "## Инструментарий\n",
    "- Python 3\n",
    "- Библиотеки [spaCy 3.0](https://spacy.io/) и [transformers 4.6](https://huggingface.co/transformers/). Мы выбрали `spacy` так как это стабильная библиотека, ориентированная на конечное использование в коммерческих приложениях.\n",
    "- Label Studio для разметки эталонного набора. \n",
    "\n",
    "## План\n",
    "- Составляем spaCy-пайплайн\n",
    "- Выделяем 10 тыс. случайных заголовков, подлежащих разметке. При случайном выборе заголовки равномерно распределены по шкале баллов от 0 до 10\n",
    "- Размечаем с помощью LabelStudio эталонный набор заголовков статей для NER. Исходно для стандартной русскоязычной модели уже имеются сущности `LOC`, `ORG`, `PER`.\n",
    "- Обучаем пайплайн заголовков на NER-задаче\n",
    "- Обучаем пайплайн на задаче регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "stem-zCmrJXk"
   },
   "outputs": [],
   "source": [
    "# Чтобы проверить версию CUDA\n",
    "#!nvcc --version\n",
    "# В зависимости от версии обновить номер плагина для CUDA\n",
    "#!pip install -U spacy[cuda110,transformers,lookups]\n",
    "# Модель для русского языка если не использовать transformers\n",
    "#!python -m spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAXUFLP850cL",
    "outputId": "7b18d1e0-8de2-46ec-9619-42d52b207009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU is used\n"
     ]
    }
   ],
   "source": [
    "# исключение для проверки, на месте ли CUDA или мы учимся на CPU\n",
    "from cupy.cuda.runtime import CUDARuntimeError\n",
    "import spacy\n",
    "import ru_core_news_lg\n",
    "\n",
    "try:\n",
    "    spacy.prefer_gpu()\n",
    "    print('CUDA GPU is used')\n",
    "except CUDARuntimeError:\n",
    "    spacy.require_cpu()\n",
    "    print('CPU is used')\n",
    "    \n",
    "nlp = ru_core_news_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7-kqtml2GLE"
   },
   "outputs": [],
   "source": [
    "# # Construction via add_pipe with custom config\n",
    "# config = {\n",
    "#     \"model\": {\n",
    "#         \"@architectures\": \"spacy-transformers.TransformerModel.v1\",\n",
    "#         \"name\": \"bert-base-multilingual-cased\",\n",
    "#         \"tokenizer_config\": {\"use_fast\": True}\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# trf = nlp.add_pipe(\"transformer\",\n",
    "#                    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pO7W9F5N7Yjx",
    "outputId": "ae6e8e62-4576-4e21-b6db-76c3d64eaf45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Пример', 'NOUN'), ('прекрасного', 'ADJ'), ('текста', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "spacy.prefer_gpu()\n",
    "nlp = ru_core_news_lg.load()\n",
    "doc = nlp(\"Пример прекрасного текста.\")\n",
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI_EefYIkDAn"
   },
   "source": [
    "Кроме имеющихся именованных сущностей мы добавляем следующие категории и подкатегории:\n",
    "1. **Объект** `OBJ`. *О чём* эта статья.  Если заголовок состоит только из таких сущностей, значит перед нами что-то вроде статьи из словаря, объяснение сущности самого объекта. Самое то для тех, кто хочет разобраться что это и зачем нужно. Примеры: \"LESS: программируемый язык стилей\", \"Composer — менеджер зависимостей для PHP\".\n",
    "2. **Аудитория** `AUD`. Для кого написан этот текст. Примеры индикаторов аудитории: \"для новичков, на Windows, профи, любой аккаунт, до 30 лет, русская версия\" Аудитория выражается и просто через \"я\" — мы сравниваем себя с другими людьми через наш общий или различный опыт. Наиболее читаемые статьи обращаются к аудитории новичков, но это не значит, что их читают только новички. \"Пайка для начинающих\", \"Hello World-проект на Flask\", \"Основы IP-телефонии\", \"Какой язык программирования стоит выучить пер\n",
    "вым?\".\n",
    "3. **Польза**. Какую проблему показывает или решает публикация. В чём ее профит?\n",
    "Польза может выражаться самыми разными способами:\n",
    "  + **Маркеры типа текста** `TYPE`: инструкция (\"как установить\", \"Шаблон базовой настройки маршрутизатора Cisco\"), определение (\"что такое... и с чем едят\"), новость (Новое в Java 8\"), личный опыт, сравнение объектов (\"X или Y\", \"Python vs R\") и т. д. По маркеру типа текста мы понимаем, с чем имеем дело.\n",
    "  + **Указание числа используемых источников или рассматриваемых объектов** `NUM`: \"10 лучших\", \"ТОП-3\".\n",
    "  + **Усилия и время, которые потратит читатель на саму статью или процесс** `EFFORT`: \"За 15 минут, за один вечер, за один год, краткое руководство, в 11 строчек кода\". Вполне возможно, что у человека достаточно времени, и он хочет детально во всём разобраться: \"Подробно о..., всё про...\". Главное, что вся нужная информация нашлась в одном месте.\n",
    "  + **Маркеры последовательного подхода, нового типа изложения** `STRUCT`. В интернете не хватает структурированной информации, люди любят когда рассказывают \"по порядку, детально, без воды\".\n",
    "  + **Предостережение об опасности или возможной ошибке** `DANGER`: \"Проблема в ... и ее их решение\", \"Взлом... от которого не спасёт\", \" \"X – ловушка для неопытных. Осторожно\".\n",
    "  + **Маркировка акта длинного повествования** `PART`. Указание части в заголовке подсказывает: перед нами часть большого текста. Хорошо работает следующий формат: \"Общее название группы технологий. Часть N. Название технологии.\"  Примеры: \"jQuery для начинающих. Часть 3. AJAX\". \"Bash-скрипты, часть 2: циклы\". \"Пишем игры на C++, Часть 1/3 — Написание мини-фреймворка\", \"Сети для самых маленьких. Часть шестая. Динамическая маршрутизация\".\n",
    "4. **Источник движения** — в хороших статьях заложена история путешествия, они приводят читателя из пункта А в пункт Б. Саму историю расскажет статья, но полезно прочертить вектор с помощью глагола, или если придется к месту — искренней эмоции.\n",
    "  + **Побуждение к действию или само действие** `TODO`. Что мы будем делать в этой статье. \"Пишем программу...\", \"настройка, обзор, запуск, ремонт\". Примеры: \"Извлекаем золото из старой электроники\", \"Запуск старых игр на Windows\".\n",
    "  + **Эмоция** `EMO`. С эмоциями не стоит перебарщивать, но иногда сильная эмоция или выражение отношения — то, что нужно. \"Xудшее, что могло с нами случиться.\" \"Почему научиться программировать так чертовски тяжело?\". Помните: читатель не дурак, эмоции в заголовке работают только, если они неподдельные.\n",
    "\n",
    "Помните, что каким бы ни был заголовок, главное – сам текст и внимательное отношение к читателю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(\"./output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Что нужно знать о проблемах молодой аудитории\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\"Что нужно знать о проблемах молодой аудитории\")\n",
    "\n",
    "spacy.displacy.render(doc,\n",
    "                      style=\"ent\",\n",
    "                      jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 22:18:08.656070: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-05-27 22:18:08.656101: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
      "into documents with `-n 10`.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (1731 documents): train.spacy\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!spacy convert train.conll ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 22:18:15.265706: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-05-27 22:18:15.265741: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-05-27 22:18:17,230] [INFO] Set up nlp object from config\n",
      "[2021-05-27 22:18:17,237] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-05-27 22:18:17,240] [INFO] Created vocabulary\n",
      "[2021-05-27 22:18:17,240] [INFO] Finished initializing nlp object\n",
      "[2021-05-27 22:18:18,700] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     70.35    0.51    1.79    0.30    0.01\n",
      "  1     200        102.84   9564.77   48.65   62.65   39.77    0.49\n",
      "  3     400        285.68   8786.63   66.94   69.30   64.75    0.67\n",
      "  6     600        554.91   7819.11   87.00   87.82   86.19    0.87\n",
      "  9     800        611.20   5568.39   94.88   94.82   94.94    0.95\n"
     ]
    }
   ],
   "source": [
    "!spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "iTitle_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
