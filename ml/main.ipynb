{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание задачи\n",
    "\n",
    "**Цель**: сделать веб-приложение, помогающее авторам и редакторам IT-публикаций подбирать к ним удачные заголовки.\n",
    "\n",
    "**Задача-минимум**: создать сервис, который учит пользователя (автора, редактора) использовать разумные подходы для составления говорящего заголовка. По такому заголовку читатель понимает, какую пользу он получит от прочтения статьи.\n",
    "\n",
    "**Идея MVP**. Проблему можно сформулировать в виде задачи распознавания именованных сущностей (англ. [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition), NER). Распознанные именованные сущности можно далее вмесе с токенизированным текстом использовать для выставления условного балла от 0 до 10, позволяющего автору быстро оценить результат.\n",
    "\n",
    "**Задача-минимум**: веб-страница, на которой пользователь вводит строку заголовка, а в ответ получает:\n",
    "1) оценка заголовка,\n",
    "2) найденные полезные индикаторы\n",
    "3) подсказки, что далее делать с заголовком.\n",
    "\n",
    "**Задача-максимум** (пока не решаем): генерация вариантов более качественных заголовков по тексту публикации или сочетанию чернового заголовка и краткого содержания.\n",
    "\n",
    "# Инструментарий\n",
    "- Python 3\n",
    "- NLP-библиотека [spaCy 3.0](https://spacy.io/). Мы выбрали `spacy` так как это стабильная библиотека, ориентированная на конечное использование в коммерческих приложениях. Однако 3-я версия не очень хорошо зарекомендовала для себя для классификации большого набора данных, а transformers оказалась слишком долгой для обучения и медленной для задачи веб-сервиса. Поэтому мы использовали быстрый CatBoost.\n",
    "- ML-библиотека CatBoost (использовалась для оценки возможности построения ML-модели, на деле не применяется).\n",
    "\n",
    "Для разметки эталонного набора именованных сущностей использовалось [Label Studio](https://labelstud.io/). Вручную было размечено 3000 заголовков, далее эти результаты использовались для полуавтоматической разметки. Для разметки данных мы использовали стандартный формат [CoNLL](https://www.signll.org/conll/) ([StackOverflow discussion](https://stackoverflow.com/questions/27416164/what-is-conll-data-format)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import PIPE, run\n",
    "from itertools import combinations\n",
    "import json\n",
    "\n",
    "# библиотеки обработки данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# прогрессбар\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# natural language processing\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# ml models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, minmax_scale, quantile_transform\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# фильтрация некритичных предупреждений pandas b jupyter\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\",\n",
    "                      category=SettingWithCopyWarning)\n",
    "\n",
    "DATASETS_PATH = '../../DATASETS/title'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка текстового корпуса\n",
    "\n",
    "## 1.1. Изучим датасет, содержащий заголовки и число просмотров\n",
    "\n",
    "С помощью веб-парсинга мы собрали большое количество данных в один общий датасет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df():\n",
    "    df = pd.read_feather(f'{DATASETS_PATH}/total.feather')    \n",
    "    df = df.set_index('url')  # feather doesn't work with str indices\n",
    "    \n",
    "    # parse timing cols ad datetime\n",
    "    for col in ('post_time', 'parse_time'):\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = read_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение статей по источникам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. ML-коррекция заниженного количества просмотров\n",
    "\n",
    "Количество просмотров на сайтах иногда значительно отстает от ожидаемого или не всегда рассчитывается правильно.\n",
    "\n",
    "Например, для новых статей или статей, изменивших статус публичности. Особенно это заметно, когда количество просмотров меньше количества лайков и закладок. Чтобы исправить такие значения, построим простую регрессионную модель на данных, которым мы можем доверять. Далее экстраполируем результат на «подозрительные» данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timedelta'] = (df.parse_time - df.post_time).apply(lambda x: x.total_seconds())*1e-6\n",
    "df_tmp = df[['likes_num', 'favs_num', 'comments_num', 'views_num', 'source', 'timedelta']].dropna()\n",
    "\n",
    "# for categorical data (source feature)\n",
    "df_tmp = pd.get_dummies(df_tmp)\n",
    "df_tmp['suspicious'] = [False]*df_tmp.shape[0]\n",
    "for col in ('likes', 'favs', 'comments'):\n",
    "    df_tmp['suspicious'] += df_tmp[f'{col}_num'] > 0.1*df_tmp['views_num']\n",
    "\n",
    "df_tmp_susp = df_tmp[df_tmp['suspicious'] == True]\n",
    "df_tmp = df_tmp[df_tmp['suspicious'] == False]\n",
    "\n",
    "df_tmp = df_tmp.drop(columns=['suspicious'])\n",
    "df_tmp_susp = df_tmp_susp.drop(columns=['suspicious'])\n",
    "\n",
    "y = df_tmp['views_num']\n",
    "X = df_tmp.drop(columns=['views_num'])\n",
    "reg = make_pipeline(StandardScaler(),\n",
    "                    RandomForestRegressor(n_jobs=20))\n",
    "reg.fit(X, y)\n",
    "df_tmp_susp['views_num'] = reg.predict(df_tmp_susp.drop(columns=['views_num']))\n",
    "df_tmp_susp['views_num'] = df_tmp_susp['views_num'].apply(round)\n",
    "df_tmp = pd.concat([df_tmp, df_tmp_susp])\n",
    "\n",
    "df.update(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем исключить данные, которые не содержат числа просмотров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['views_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее не будем учитывать сайты, на которых были размещены публикации. Нормируем число просмотров для статей определенного источника на максимальное для каждого из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in df.source.unique():\n",
    "    cond = (df.source == s)\n",
    "    m = df.loc[cond].views_num.max()\n",
    "    df.loc[cond, 'views_num'] /= m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Отбор признаков для работы\n",
    "\n",
    "**Число просмотров** — наша целевая переменная.\n",
    "\n",
    "**Время от публикации до парсинга**. Важной характеристикой публикации является то, когда она была опубликована. Тематики статей меняются, растет число людей с доступом в интернет. Со временем статьи с актуальными темами продолжают получать дочитывания, а наиболее новые статьи еще не набрали своего. В результате мы имеем следующее распределение просмотров относительно шкалы времени:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(-df.timedelta,\n",
    "            df.views_num,\n",
    "            s = 5,\n",
    "            marker='.')\n",
    "plt.xlabel('Время, усл. ед.')\n",
    "plt.ylabel('Число просмотров.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для новых публикаций мы будем указывать нулевую отметку времени.\n",
    "\n",
    "В результате мы используем сами тексты заголовков, число просмотров и интервал времени, за который число просмотров было набрано:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = df[['timedelta', 'title', 'views_num']].reset_index(drop=True)\n",
    "Xy.views_num = Xy.views_num.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Предобработка числовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью z-оценки выкинем явные выбросы (оказалось, что это примерно 5 тыс. статей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy['z_score'] = stats.zscore(Xy['views_num'])\n",
    "Xy = Xy.loc[Xy['z_score'].abs()<=3]\n",
    "Xy = Xy.drop(columns=['z_score'])\n",
    "Xy.reset_index(drop=True, inplace=True)\n",
    "print(Xy.shape)\n",
    "\n",
    "plt.scatter(-Xy.timedelta,\n",
    "            Xy.views_num,\n",
    "            s = 0.01,\n",
    "            marker='.')\n",
    "plt.xlabel('Время, усл. ед.')\n",
    "plt.ylabel('Число просмотров.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гистограмма распределния числа просмотров: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Xy.views_num, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кривая имеет предсказуемый характер, поэтому мы можем воспользоваться  преобразованием [Quantile Transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.quantile_transform.html#sklearn.preprocessing.quantile_transform), чтобы трансформировать распределение к нормальному виду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Xy.views_num.to_numpy().reshape(-1, 1)\n",
    "Xy['y'] = quantile_transform(y, output_distribution='normal')\n",
    "plt.hist(Xy['y'], bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для переменной времени применим обычную нормировку по интервалу, чтобы данные лежали в диапазоне `[0, 1]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.timedelta = minmax_scale(Xy.timedelta)\n",
    "plt.hist(Xy.timedelta, bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение модели распознавания именованных сущностей (модель NER)\n",
    "\n",
    "В качестве базовой модели `spacy` мы используем `ru_core_news_lg`. В ней уже имеются сущности `PER` (персоналий), организаций (`ORG`), географических локаций (`LOC`). Кроме имеющихся именованных сущностей мы добавили в разметку следующие категории и подкатегории:\n",
    "\n",
    "1. **Объект** `OBJ`. *О чём* эта статья.  Если заголовок состоит только из таких сущностей, значит перед нами что-то вроде статьи из словаря — объяснение сущности самого объекта. Примеры: \"LESS: программируемый язык стилей\", \"Composer — менеджер зависимостей для PHP\".\n",
    "2. **Аудитория** `AUD`. Для кого написан этот текст. Примеры индикаторов аудитории: \"для новичков, на Windows, профи, любой аккаунт, до 30 лет, русская версия\" Аудитория выражается и просто через \"я\" — мы сравниваем себя с другими людьми через наш общий или различный опыт. Наиболее читаемые статьи обращаются к аудитории новичков, но это не значит, что их читают только новички. \"Пайка для начинающих\", \"Hello World-проект на Flask\", \"Основы IP-телефонии\", \"Какой язык программирования стоит выучить пер\n",
    "вым?\".\n",
    "3. **Польза**. Какую проблему показывает или решает публикация. В чём ее профит?\n",
    "Польза может выражаться самыми разными способами:\n",
    "      + **Маркеры типа текста** `TYPE`: инструкция (\"как установить\", \"Шаблон базовой настройки маршрутизатора Cisco\"), определение (\"что такое... и с чем едят\"), новость (Новое в Java 8\"), личный опыт, сравнение объектов (\"X или Y\", \"Python vs R\") и т. д. По маркеру типа текста мы понимаем, с чем имеем дело.\n",
    "     + **Указание числа используемых источников или рассматриваемых объектов** `NUM`: \"10 лучших\", \"ТОП-3\".\n",
    "     + **Усилия и время, которые потратит читатель на саму статью или процесс** `EFFORT`: \"За 15 минут, за один вечер, за один год, краткое руководство, в 11 строчек кода\". Вполне возможно, что у человека достаточно времени, и он хочет детально во всём разобраться: \"Подробно о..., всё про...\". Главное, что вся нужная информация нашлась в одном месте.\n",
    "    + **Маркеры последовательного подхода, нового типа изложения** `STRUCT`. В интернете не хватает структурированной информации, люди любят когда рассказывают \"по порядку, детально, без воды\".\n",
    "    + **Предостережение об опасности или возможной ошибке** `DANGER`: \"Проблема в ... и ее их решение\", \"Взлом... от которого не спасёт\", \" \"X – ловушка для неопытных. Осторожно\".\n",
    "    + **Маркировка акта длинного повествования** `PART`. Указание части в заголовке подсказывает: перед нами часть большого текста. Хорошо работает следующий формат: \"Общее название группы технологий. Часть N. Название технологии.\"  Примеры: \"jQuery для начинающих. Часть 3. AJAX\". \"Bash-скрипты, часть 2: циклы\". \"Пишем игры на C++, Часть 1/3 — Написание мини-фреймворка\", \"Сети для самых маленьких. Часть шестая. Динамическая маршрутизация\".\n",
    "    + **Преимущество получаемое читателем**: бесплатно, своими руками, в домашних условиях\n",
    "4. **Источник движения** — в хороших статьях заложена история путешествия, они приводят читателя из пункта А в пункт Б. Саму историю расскажет статья, но полезно прочертить вектор с помощью глагола, или если придется к месту — искренней эмоции.\n",
    "    + **Побуждение к действию или само действие** `TODO`. Что мы будем делать в этой статье. \"Пишем программу...\", \"настройка, обзор, запуск, ремонт\". Примеры: \"Извлекаем золото из старой электроники\", \"Запуск старых игр на Windows\".\n",
    "    + **Эмоция** `EMO`. С эмоциями не стоит перебарщивать, но иногда сильная эмоция или выражение отношения — то, что нужно. \"Xудшее, что могло с нами случиться.\" \"Почему научиться программировать так чертовски тяжело?\". Помните: читатель не дурак, эмоции в заголовке работают только, если они неподдельные.\n",
    "\n",
    "Однако нужно помнить, что каким бы ни был заголовок, главное – сам текст и внимательное отношение к читателю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out(command):\n",
    "    '''Выводит данные '''\n",
    "    result = run(command, stdout=PIPE,\n",
    "                 stderr=PIPE, universal_newlines=True,\n",
    "                 shell=True)\n",
    "    return result.stdout\n",
    "\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"./nlp_model/model-best\")\n",
    "except OSError:\n",
    "    # если модель ещё не обучалась\n",
    "    # используем в качестве старта предобученную\n",
    "    import ru_core_news_lg\n",
    "    nlp = ru_core_news_lg.load()\n",
    "    # это всего лишь прямые вызовы из командной строки\n",
    "    print(out('spacy init fill-config nlp_model/base_config.cfg nlp_model/config.cfg'))\n",
    "    print(out('spacy convert nlp_model/train_data/title_ner.conll nlp_model/train_data -n 10'))\n",
    "    !spacy train ./nlp_model/config.cfg --output ./nlp_model --paths.train ./nlp_model/train_data/title_ner.spacy --paths.dev ./nlp_model/train_data/title_ner.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Совет**: в случае, если spacy-файл не создается, проверьте корректность conll-файла с помощью регулярного выражения: `^(?!(.+ -X- .+\\n)|\\n)` — оно отберет всё, что не соответствует формату.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На нескольких примерах проверим корректность поиска именованных сущностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ТОП-3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    книги\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
       "</mark>\n",
       " о \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    языке программирования\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">OBJ</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Всё, что вы хотели знать\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
       "</mark>\n",
       " о \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JavaScript\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANG</span>\n",
       "</mark>\n",
       ", но боялись спросить.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Новые возможности\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADV</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ubuntu\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">OS</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    20.04\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VERSION</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# в файле tags.json хранятся данные \n",
    "with open(f'nlp_model/tags.json') as f:\n",
    "    tags = json.load(f)\n",
    "\n",
    "# определим, какие сущности мы зарезервировали\n",
    "tag_names = list(tags.keys())\n",
    "\n",
    "examples = ['ТОП-3 книги о языке программирования Python',\n",
    "            'Всё, что вы хотели знать о JavaScript, но боялись спросить.',\n",
    "            'Новые возможности Ubuntu 20.04.'\n",
    "           ]\n",
    "\n",
    "colors = {\"LANG\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "options = {\"ents\": tag_names, \"colors\": colors}\n",
    "\n",
    "for example in examples:\n",
    "    doc = nlp(example)\n",
    "    html = displacy.render(doc, style=\"ent\",\n",
    "                    options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь применим NER-модель к текстовой составляющей — признаку `title`. Определим, какие сущности (`ents`) встречаются и какова их доля (`fraction`) от общей длины заголовка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_ents(s):\n",
    "    seq = nlp(s).ents\n",
    "    labels, indices = [], []\n",
    "    for ent in seq:\n",
    "        if ent.label_ in tag_names:\n",
    "            labels.append(ent.label_)\n",
    "            indices.append([ent.start_char, ent.end_char])\n",
    "    try:\n",
    "        fraction = len(''.join(str(ent) for ent in seq))/len(s)            \n",
    "    except ZeroDivisionError:\n",
    "        fraction = 0.0\n",
    "    return labels, fraction, indices\n",
    "\n",
    "\n",
    "try:\n",
    "    # распознавание сущностей для большого массива\n",
    "    # это трудоемкая операция, поэтому мы сохраняем результат\n",
    "    # и загружаем его, если уже был проведен расчет\n",
    "    Xy = pd.read_csv(f'{DATASETS_PATH}/Xy_ents.csv',\n",
    "                     index_col=0)\n",
    "    Xy.ents = Xy.ents.apply(eval)\n",
    "except FileNotFoundError:\n",
    "    Xy['ents'] = Xy.title.progress_apply(str_to_ents)\n",
    "    Xy['ents_fraction'] = Xy['ents'].apply(lambda x: x[1])\n",
    "    Xy['ents'] = Xy['ents'].apply(lambda x: x[0])\n",
    "    Xy.to_csv(f'{DATASETS_PATH}/Xy_ents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем полученные данные об именованных сущностях к числовому представлению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8273ccf2bc46e9b895f82c647afdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=306402.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>title</th>\n",
       "      <th>views_num</th>\n",
       "      <th>y</th>\n",
       "      <th>ents</th>\n",
       "      <th>ents_fraction</th>\n",
       "      <th>PER</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "      <th>OBJ</th>\n",
       "      <th>...</th>\n",
       "      <th>MATH</th>\n",
       "      <th>GAME</th>\n",
       "      <th>NEWS</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>COND</th>\n",
       "      <th>APP</th>\n",
       "      <th>VERSION</th>\n",
       "      <th>LIB</th>\n",
       "      <th>FRAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006861</td>\n",
       "      <td>Blackbox-сканеры в процессе оценки безопасност...</td>\n",
       "      <td>0.023319</td>\n",
       "      <td>1.963925</td>\n",
       "      <td>[TYPE, AUD, OBJ, OBJ]</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006972</td>\n",
       "      <td>Инструменты управления командой разработки на ...</td>\n",
       "      <td>0.058947</td>\n",
       "      <td>2.619812</td>\n",
       "      <td>[TYPE, OBJ, COND]</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006989</td>\n",
       "      <td>Стоит поиграть: обзор игры 7 Billion Humans</td>\n",
       "      <td>0.081565</td>\n",
       "      <td>2.925361</td>\n",
       "      <td>[TYPE, TYPE, OBJ, GAME]</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007087</td>\n",
       "      <td>Как снизить расходы на разработку программного...</td>\n",
       "      <td>0.078663</td>\n",
       "      <td>2.889142</td>\n",
       "      <td>[ADV, OBJ]</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007103</td>\n",
       "      <td>Моя история в IT: от любви к математике до меж...</td>\n",
       "      <td>0.071457</td>\n",
       "      <td>2.780683</td>\n",
       "      <td>[TYPE, EMO, OBJ, ORG, NUM, OBJ]</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta                                              title  views_num  \\\n",
       "0   0.006861  Blackbox-сканеры в процессе оценки безопасност...   0.023319   \n",
       "1   0.006972  Инструменты управления командой разработки на ...   0.058947   \n",
       "2   0.006989        Стоит поиграть: обзор игры 7 Billion Humans   0.081565   \n",
       "3   0.007087  Как снизить расходы на разработку программного...   0.078663   \n",
       "4   0.007103  Моя история в IT: от любви к математике до меж...   0.071457   \n",
       "\n",
       "          y                             ents  ents_fraction  PER  ORG  LOC  \\\n",
       "0  1.963925            [TYPE, AUD, OBJ, OBJ]       0.758621    0    0    0   \n",
       "1  2.619812                [TYPE, OBJ, COND]       0.679487    0    0    0   \n",
       "2  2.925361          [TYPE, TYPE, OBJ, GAME]       0.930233    0    0    0   \n",
       "3  2.889142                       [ADV, OBJ]       0.932203    0    0    0   \n",
       "4  2.780683  [TYPE, EMO, OBJ, ORG, NUM, OBJ]       0.840426    0    1    0   \n",
       "\n",
       "   OBJ  ...  MATH  GAME  NEWS  CONF  ACTUAL  COND  APP  VERSION  LIB  FRAME  \n",
       "0    2  ...     0     0     0     0       0     0    0        0    0      0  \n",
       "1    1  ...     0     0     0     0       0     1    0        0    0      0  \n",
       "2    1  ...     0     1     0     0       0     0    0        0    0      0  \n",
       "3    1  ...     0     0     0     0       0     0    0        0    0      0  \n",
       "4    2  ...     0     0     0     0       0     0    0        0    0      0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ents_to_array(ents_list):\n",
    "    '''Преобразует список именованных сущностей\n",
    "    для одного заголовка в массив чисел,\n",
    "    где индекс соответствует номеру сущности,\n",
    "    а число - количеству появлений в заголовке'''\n",
    "    line = [0]*len(tag_names)\n",
    "    for t in ents_list:\n",
    "        try:\n",
    "            i = tag_names.index(t)\n",
    "            line[i] += 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return np.array(line, dtype=np.uint8)\n",
    "\n",
    "ents_array = Xy.ents.progress_apply(ents_to_array)\n",
    "data = np.array(ents_array.to_list())\n",
    "tmp = pd.DataFrame(data, columns=tag_names)\n",
    "Xy = pd.concat([Xy, tmp], axis = 1)\n",
    "Xy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на корреляцию признаков и числа просмотров `views_num` (без нелинейных преобразований `y`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = Xy.drop(columns=['y']).corr()\n",
    "correlations['views_num'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Относительно тегов мы можем предположить, что указание типа (`TYPE`),  используемой технологии (`TECH`), целевой аудитории `AUD` и совершаемого действия (`TODO`) обычно приводят к увеличению числа просмотров.\n",
    "\n",
    "Указание опасности (`DANGER`), организации, персоны, локации (`ORG`, `PER`, `LOC`), конкретной программы (`PROGRAM`), конференции (`CONF`),видимо, в большей мере относятся к новостям, которые быстро теряют актуальности. Поэтому такие атрибуты связаны с уменьшением количества просмотров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.drop(columns=['title', 'views_num', 'ents', 'y'])\n",
    "y = Xy.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сами корреляции коэффициенты корреляции в абсолютном значении невелики. Поэтому большее внимание надо отдавать языковой модели. Предварительно попробуем поискать композитные фичи, используя пары и тройки столбцов с тегами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ents = X.drop(columns=['timedelta', 'ents_fraction'])\n",
    "from itertools import combinations\n",
    "\n",
    "cc2 = list(combinations(X_ents.columns,2))\n",
    "X_ents2 = pd.concat([X_ents[c[0]].add(X_ents[c[1]]) for c in cc2],\n",
    "          axis=1, keys=cc2)\n",
    "\n",
    "cc3 = list(combinations(X_ents.columns,3))\n",
    "X_ents3 = pd.concat([X_ents[c[0]].add(X_ents[c[1]]).add(X_ents[c[2]]) for c in cc3],\n",
    "          axis=1, keys=cc3)\n",
    "\n",
    "X_ents2.columns = X_ents2.columns.map('_'.join)\n",
    "X_ents3.columns = X_ents3.columns.map('_'.join)\n",
    "X_ents = pd.concat([X, X_ents2, X_ents3, Xy['views_num']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "X_ents = X_ents.fillna(0)\n",
    "X_ents['BOOL'] = X.ents_fraction.apply(lambda x: x == 0)\n",
    "for col in X_ents.drop(columns=['views_num', 'timedelta', 'ents_fraction']).columns:\n",
    "    d[col] = stats.pearsonr(X_ents['views_num'], X_ents[col])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list, value_list = [], []\n",
    "\n",
    "for key in d:\n",
    "    ner_list.append(set(key.split('_')))\n",
    "    value_list.append(d[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_cor = pd.DataFrame.from_dict({'NER': ner_list, 'VALUE': value_list})\n",
    "df_ner_cor.to_csv(f'nlp_model/df_ner_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>{NUM, AUD, TYPE}</td>\n",
       "      <td>0.093732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>{TODO, AUD, TYPE}</td>\n",
       "      <td>0.091172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>{AUD, TYPE, ADV}</td>\n",
       "      <td>0.090112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>{AUD, TYPE, OS}</td>\n",
       "      <td>0.088168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>{EMO, AUD, TYPE}</td>\n",
       "      <td>0.086781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>{LOC, ANNOUNCE, PROGRAM}</td>\n",
       "      <td>-0.029263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>{LOC, SITE, PROGRAM}</td>\n",
       "      <td>-0.029266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>{LOC, PROGRAM}</td>\n",
       "      <td>-0.029470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>{NEWS, LOC, PROGRAM}</td>\n",
       "      <td>-0.029722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>{LOC, CONF, PROGRAM}</td>\n",
       "      <td>-0.030294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NER     VALUE\n",
       "2066          {NUM, AUD, TYPE}  0.093732\n",
       "2071         {TODO, AUD, TYPE}  0.091172\n",
       "2073          {AUD, TYPE, ADV}  0.090112\n",
       "2076           {AUD, TYPE, OS}  0.088168\n",
       "2072          {EMO, AUD, TYPE}  0.086781\n",
       "...                        ...       ...\n",
       "1626  {LOC, ANNOUNCE, PROGRAM} -0.029263\n",
       "1625      {LOC, SITE, PROGRAM} -0.029266\n",
       "104             {LOC, PROGRAM} -0.029470\n",
       "1629      {NEWS, LOC, PROGRAM} -0.029722\n",
       "1630      {LOC, CONF, PROGRAM} -0.030294\n",
       "\n",
       "[4992 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner_cor.sort_values(by='VALUE', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метке `BOOL` соответствует полное отсутствие каких-либо сущностей. Таким образом, хотя бы минимальное соответствие, даже худшим по корреляциям из меток, лучше, чем ничего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Обучение регрессионной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы привели текстовые данные к числовому представлению и теперь можем заняться задачей регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ents.drop(columns=['views_num']), y,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении используем структуру `Pool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 10000,\n",
    "    'learning_rate': 0.01,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'early_stopping_rounds': 100,\n",
    "    'use_best_model': True\n",
    "}\n",
    "\n",
    "def fit_model(X_train, y_train, X_test, y_test, catboost_params):\n",
    "    train_pool = Pool(data = X_train,\n",
    "                      label = y_train)\n",
    "\n",
    "    validation_pool = Pool(data = X_test,\n",
    "                           label = y_test)\n",
    "\n",
    "    model = CatBoostRegressor(**catboost_params)\n",
    "\n",
    "    return model.fit(train_pool,\n",
    "                     eval_set=validation_pool,\n",
    "                     verbose=100)\n",
    "\n",
    "\n",
    "model = fit_model(X_train, y_train,\n",
    "                  X_test, y_test,\n",
    "                  catboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE(model.predict(X_test), y_test))\n",
    "plt.scatter(model.predict(X_test), y_test, s=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вполне ожидаемо (и прискорбно), но регресионная модель обучается довольно слабо: на число просмотров оказывают влияния множество иных факторов, а не только сами сущности.\n",
    "\n",
    "Использование трансформерной модели или других моделей, работающих с сутью текста, повысило бы качество, но усложнило бы коррекцию заголовка пользователем: балл оценки в таком случае сложно интерпретируется, возможны только действия \"наугад\". Однако такое решение можно использовать в будущем для генеративного подхода поиска заголовка.\n",
    "\n",
    "Поэтому в конечном итоге мы использовали подход программного определения правил, исходя из лучших сочетаний сущностей. Результат реализован сразу в виде py-файла `corr_model.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Дополнительная разметка NER-модели\n",
    "\n",
    "Для коррекции результатов NER-модели, проведем поиск сущностей для остальных заголовков в формате conll-файла, который далее проверим вручную и дообучим модель. Для этого напишем вспомогательную функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titles_to_conll(titles:list):\n",
    "    '''Преобразует список заголовков к conll-файлу\n",
    "    для обучения spacy'''\n",
    "    with open('output.conll', 'w') as f:\n",
    "        f.write('-DOCSTART- -X- O O\\n')\n",
    "        for title in tqdm(titles):\n",
    "            doc = nlp(title)\n",
    "            for tok in doc:\n",
    "                if tok.ent_type_:\n",
    "                    f.write(f'{tok} -X- {tok.ent_iob_}-{tok.ent_type_}\\n')\n",
    "                else:\n",
    "                    f.write(f'{tok} -X- O\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_to_conll(df.title.to_list()[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заключение\n",
    "\n",
    "По итогам работы выполнено следующее:\n",
    "1. Собраны данные о 300 тыс. публикациях из мира IT и смежных областей. Датасет включает заголовки, информацию о числе просмотров, различные виды откликов, даты публикации, краткие описания (лиды). Адрес датасета: `DATASETS/title/total.feather` (`.feather` — формат для быстрой загрузки в `pandas`).\n",
    "2. На 3 тыс. заголовков осуществлена ручная разметка именованных сущностей (`title/ml/nlp_model/train_data/title_ner.conll`), которая далее использовалась для автоматической разметки корпуса. Этот же инструмент можно использовать для дальнейшего улучшения модели: автоматически размечать корпус и валидировать результат. На текущий момент так размечено 31 тыс. токенов.\n",
    "3. На размеченных данных обучена модель (`title/ml/nlp_model/model-best`), которая реализует поиск именованных сущностей в заголовках.\n",
    "4. На базе предыдущей модели построена регресионная модель (`title/ml/nlp_model/corr_model.py`), которая предсказывает числовую оценку по 10-балльной шкале и делает предложения пользователю для повышения числовой оценки. Процесс работы над обеими моделями описан в `title/ml/main.ipynb`.\n",
    "5. На основе двух описанных моделей создано веб-приложение на фреймворке Django. Приложение осуществляет взаимодействие пользователя с описанными моделями и сохраняет результаты в базу данных PostgreSQL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
