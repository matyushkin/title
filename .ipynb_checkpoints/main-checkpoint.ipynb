{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Текущий план\n",
    "- попробовать оформить и обучить отдельно текстовый регрессор (классификатор) на spacy - можно сделать в отдельном файле test.ipynb, там уже описано как делать, и мы имеем достаточно примеров\n",
    "- добавляем вектора из spacy\n",
    "\n",
    "Идея: см. какие теги нашлись, проверяем, какое количество просмотров предсказала бы модель для худшего и лучшего сценария, и находим, где между минимумом и максимумом находится наша точка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание задачи\n",
    "\n",
    "**Цель**: сделать веб-приложение, помогающее авторам и редакторам IT-публикаций подбирать к ним удачные заголовки.\n",
    "\n",
    "**Задача-минимум**: создать сервис, который учит пользователя (автора, редактора) использовать разумные подходы для составления говорящего заголовка. По такому заголовку читатель понимает, какую пользу он получит от прочтения статьи.\n",
    "\n",
    "**Идея MVP**. Проблему можно сформулировать в виде задачи распознавания именованных сущностей (англ. [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition), NER). Распознанные именованные сущности можно далее вмесе с токенизированным текстом использовать для выставления условного балла от 0 до 10, позволяющего автору быстро оценить результат.\n",
    "\n",
    "**Задача-минимум**: веб-страница, на которой пользователь вводит строку заголовка, а в ответ получает:\n",
    "1) оценка заголовка,\n",
    "2) найденные полезные индикаторы\n",
    "3) подсказки, что далее делать с заголовком.\n",
    "\n",
    "**Задача-максимум** (пока не решаем): генерация вариантов более качественных заголовков по тексту публикации или сочетанию чернового заголовка и краткого содержания.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструментарий\n",
    "- Python 3\n",
    "- NLP-библиотека [spaCy 3.0](https://spacy.io/). Мы выбрали `spacy` так как это стабильная библиотека, ориентированная на конечное использование в коммерческих приложениях. Однако 3-я версия не очень хорошо зарекомендовала для себя для классификации большого набора данных, а transformers оказалась слишком долгой для обучения и медленной для задачи веб-сервиса. Поэтому мы использовали быстрый CatBoost.\n",
    "- ML-библиотека CatBoost\n",
    "\n",
    "Для разметки эталонного набора именованных сущностей использовалось [Label Studio](https://labelstud.io/). Вручную было размечено 3000 заголовков, далее эти результаты использовались для полуавтоматической разметки. Для разметки данных мы использовали стандартный формат [CoNLL format](https://www.signll.org/conll/) ([StackOverflow discussion](https://stackoverflow.com/questions/27416164/what-is-conll-data-format))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import PIPE, run\n",
    "import json\n",
    "\n",
    "# библиотеки обработки данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# прогрессбар\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# natural language processing\n",
    "import spacy\n",
    "\n",
    "# ml models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, minmax_scale, quantile_transform\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# фильтрация некритичных предупреждений pandas b jupyter\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\",\n",
    "                      category=SettingWithCopyWarning)\n",
    "\n",
    "DATASETS_PATH = '../DATASETS/title'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка текстового корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Изучим датасет, содержащий заголовки и число просмотров\n",
    "\n",
    "С помощью веб-парсинга мы собрали большое количество данных в один общий датасет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df():\n",
    "    df = pd.read_feather(f'{DATASETS_PATH}/total.feather')    \n",
    "    df = df.set_index('url')  # feather doesn't work with str indices\n",
    "    \n",
    "    # parse timing cols ad datetime\n",
    "    for col in ('post_time', 'parse_time'):\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = read_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение статей по источникам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. ML-коррекция заниженного количества просмотров\n",
    "\n",
    "Количество просмотров на сайтах иногда значительно отстает от ожидаемого или не всегда рассчитывается правильно.\n",
    "\n",
    "Например, для новых статей или статей, изменивших статус публичности. Особенно это заметно, когда количество просмотров меньше количества лайков и закладок. Чтобы исправить такие значения, построим простую регрессионную модель на данных, которым мы можем доверять. Далее экстраполируем результат на «подозрительные» данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timedelta'] = (df.parse_time - df.post_time).apply(lambda x: x.total_seconds())*1e-6\n",
    "df_tmp = df[['likes_num', 'favs_num', 'comments_num', 'views_num', 'source', 'timedelta']].dropna()\n",
    "\n",
    "# for categorical data (source feature)\n",
    "df_tmp = pd.get_dummies(df_tmp)\n",
    "df_tmp['suspicious'] = [False]*df_tmp.shape[0]\n",
    "for col in ('likes', 'favs', 'comments'):\n",
    "    df_tmp['suspicious'] += df_tmp[f'{col}_num'] > 0.1*df_tmp['views_num']\n",
    "\n",
    "df_tmp_susp = df_tmp[df_tmp['suspicious'] == True]\n",
    "df_tmp = df_tmp[df_tmp['suspicious'] == False]\n",
    "\n",
    "df_tmp = df_tmp.drop(columns=['suspicious'])\n",
    "df_tmp_susp = df_tmp_susp.drop(columns=['suspicious'])\n",
    "\n",
    "y = df_tmp['views_num']\n",
    "X = df_tmp.drop(columns=['views_num'])\n",
    "reg = make_pipeline(StandardScaler(),\n",
    "                    RandomForestRegressor(n_jobs=20))\n",
    "reg.fit(X, y)\n",
    "df_tmp_susp['views_num'] = reg.predict(df_tmp_susp.drop(columns=['views_num']))\n",
    "df_tmp_susp['views_num'] = df_tmp_susp['views_num'].apply(round)\n",
    "df_tmp = pd.concat([df_tmp, df_tmp_susp])\n",
    "\n",
    "df.update(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем исключить данные, которые не содержат числа просмотров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['views_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы не будем учитывать сайт, на котором размещена публикация, поэтому нормируем число просмотров для статей определенного источника на максимальное для каждого из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in df.source.unique():\n",
    "    cond = (df.source == s)\n",
    "    m = df.loc[cond].views_num.max()\n",
    "    df.loc[cond, 'views_num'] /= m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Отбор признаков для работы\n",
    "\n",
    "**Число просмотров** — наша целевая переменная.\n",
    "\n",
    "**Время от публикации до парсинга**. Важной характеристикой публикации является то, когда она была опубликована. Тематики статей меняются, растет число людей с доступом в интернет. Со временем статьи с актуальными темами продолжают получать дочитывания, а наиболее новые статьи еще не набрали своего. В результате мы имеем следующее распределение просмотров относительно шкалы времени:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(-df.timedelta,\n",
    "            df.views_num,\n",
    "            s = 5,\n",
    "            marker='.')\n",
    "plt.xlabel('Время, усл. ед.')\n",
    "plt.ylabel('Число просмотров.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для новых публикаций мы будем указывать нулевую отметку времени.\n",
    "\n",
    "В результате мы используем сами тексты заголовков, число просмотров и интервал времени, за который число просмотров было набрано:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = df[['timedelta', 'title', 'views_num']].reset_index(drop=True)\n",
    "Xy.views_num = Xy.views_num.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Предобработка числовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью z-оценки выкинем явные выбросы (оказалось, что это примерно 5 тыс. статей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy['z_score'] = stats.zscore(Xy['views_num'])\n",
    "Xy = Xy.loc[Xy['z_score'].abs()<=3]\n",
    "Xy = Xy.drop(columns=['z_score'])\n",
    "Xy.reset_index(drop=True, inplace=True)\n",
    "print(Xy.shape)\n",
    "\n",
    "plt.scatter(-Xy.timedelta,\n",
    "            Xy.views_num,\n",
    "            s = 0.01,\n",
    "            marker='.')\n",
    "plt.xlabel('Время, усл. ед.')\n",
    "plt.ylabel('Число просмотров.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гистограмма распределния числа просмотров: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Xy.views_num, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кривая имеет предсказуемый характер, поэтому мы можем воспользоваться  преобразованием [Quantile Transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.quantile_transform.html#sklearn.preprocessing.quantile_transform), чтобы трансформировать распределение к нормальному виду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Xy.views_num.to_numpy().reshape(-1, 1)\n",
    "Xy['y'] = quantile_transform(y, output_distribution='normal')\n",
    "plt.hist(Xy['y'], bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для переменной времени применим обычную нормировку по интервалу, чтобы данные лежали в диапазоне `[0, 1]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.timedelta = minmax_scale(Xy.timedelta)\n",
    "plt.hist(Xy.timedelta, bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение модели распознавания именованных сущностей (модель NER)\n",
    "\n",
    "В качестве базовой модели `spacy` мы используем `ru_core_news_lg`. В ней уже имеются сущности `PER` (персоналий), организаций (`ORG`), географических локаций (`LOC`). Кроме имеющихся именованных сущностей мы добавили в разметку следующие категории и подкатегории:\n",
    "\n",
    "1. **Объект** `OBJ`. *О чём* эта статья.  Если заголовок состоит только из таких сущностей, значит перед нами что-то вроде статьи из словаря — объяснение сущности самого объекта. Примеры: \"LESS: программируемый язык стилей\", \"Composer — менеджер зависимостей для PHP\".\n",
    "2. **Аудитория** `AUD`. Для кого написан этот текст. Примеры индикаторов аудитории: \"для новичков, на Windows, профи, любой аккаунт, до 30 лет, русская версия\" Аудитория выражается и просто через \"я\" — мы сравниваем себя с другими людьми через наш общий или различный опыт. Наиболее читаемые статьи обращаются к аудитории новичков, но это не значит, что их читают только новички. \"Пайка для начинающих\", \"Hello World-проект на Flask\", \"Основы IP-телефонии\", \"Какой язык программирования стоит выучить пер\n",
    "вым?\".\n",
    "3. **Польза**. Какую проблему показывает или решает публикация. В чём ее профит?\n",
    "Польза может выражаться самыми разными способами:\n",
    "  + **Маркеры типа текста** `TYPE`: инструкция (\"как установить\", \"Шаблон базовой настройки маршрутизатора Cisco\"), определение (\"что такое... и с чем едят\"), новость (Новое в Java 8\"), личный опыт, сравнение объектов (\"X или Y\", \"Python vs R\") и т. д. По маркеру типа текста мы понимаем, с чем имеем дело.\n",
    "  + **Указание числа используемых источников или рассматриваемых объектов** `NUM`: \"10 лучших\", \"ТОП-3\".\n",
    "  + **Усилия и время, которые потратит читатель на саму статью или процесс** `EFFORT`: \"За 15 минут, за один вечер, за один год, краткое руководство, в 11 строчек кода\". Вполне возможно, что у человека достаточно времени, и он хочет детально во всём разобраться: \"Подробно о..., всё про...\". Главное, что вся нужная информация нашлась в одном месте.\n",
    "  + **Маркеры последовательного подхода, нового типа изложения** `STRUCT`. В интернете не хватает структурированной информации, люди любят когда рассказывают \"по порядку, детально, без воды\".\n",
    "  + **Предостережение об опасности или возможной ошибке** `DANGER`: \"Проблема в ... и ее их решение\", \"Взлом... от которого не спасёт\", \" \"X – ловушка для неопытных. Осторожно\".\n",
    "  + **Маркировка акта длинного повествования** `PART`. Указание части в заголовке подсказывает: перед нами часть большого текста. Хорошо работает следующий формат: \"Общее название группы технологий. Часть N. Название технологии.\"  Примеры: \"jQuery для начинающих. Часть 3. AJAX\". \"Bash-скрипты, часть 2: циклы\". \"Пишем игры на C++, Часть 1/3 — Написание мини-фреймворка\", \"Сети для самых маленьких. Часть шестая. Динамическая маршрутизация\".\n",
    "4. **Источник движения** — в хороших статьях заложена история путешествия, они приводят читателя из пункта А в пункт Б. Саму историю расскажет статья, но полезно прочертить вектор с помощью глагола, или если придется к месту — искренней эмоции.\n",
    "  + **Побуждение к действию или само действие** `TODO`. Что мы будем делать в этой статье. \"Пишем программу...\", \"настройка, обзор, запуск, ремонт\". Примеры: \"Извлекаем золото из старой электроники\", \"Запуск старых игр на Windows\".\n",
    "  + **Эмоция** `EMO`. С эмоциями не стоит перебарщивать, но иногда сильная эмоция или выражение отношения — то, что нужно. \"Xудшее, что могло с нами случиться.\" \"Почему научиться программировать так чертовски тяжело?\". Помните: читатель не дурак, эмоции в заголовке работают только, если они неподдельные.\n",
    "\n",
    "Однако нужно помнить, что каким бы ни был заголовок, главное – сам текст и внимательное отношение к читателю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out(command):\n",
    "    '''Выводит данные '''\n",
    "    result = run(command, stdout=PIPE,\n",
    "                 stderr=PIPE, universal_newlines=True,\n",
    "                 shell=True)\n",
    "    return result.stdout\n",
    "\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"./ner_model/model-best\")\n",
    "except OSError:\n",
    "    # если модель ещё не обучалась\n",
    "    # используем в качестве старта предобученную\n",
    "    import ru_core_news_lg\n",
    "    nlp = ru_core_news_lg.load()\n",
    "    print(out(\"spacy init fill-config base_config.cfg config.cfg\"))\n",
    "    print(out(\"spacy convert ./train_data/title_ner.conll ./train_data/\"))\n",
    "    # это всего лишь прямой вызов из командной строки\n",
    "    !spacy train config.cfg --output ./ner_model --paths.train ./train_data/title_ner.spacy --paths.dev ./train_data/title_ner.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На нескольких примерах проверим корректность поиска именованных сущностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь применим NER-модель к текстовой составляющей — признаку `title`. Определим, какие сущности (`ents`) встречаются и какова их доля (`fraction`) от общей длины заголовка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_ents(s):\n",
    "    seq = nlp(s).ents\n",
    "    ents_list = [ent.label_ for ent in seq]\n",
    "    try:\n",
    "        fraction = len(''.join(str(ent) for ent in seq))/len(s)\n",
    "    except ZeroDivisionError:\n",
    "        fraction = 0.0\n",
    "    return ents_list, fraction\n",
    "\n",
    "\n",
    "try:\n",
    "    # распознавание сущностей для большого массива\n",
    "    # это трудоемкая операция, поэтому мы сохраняем результат\n",
    "    # и загружаем его, если уже был проведен расчет\n",
    "    Xy = pd.read_csv(f'{DATASETS_PATH}/Xy_ents.csv',\n",
    "                     index_col=0)\n",
    "    Xy.ents = Xy.ents.apply(eval)\n",
    "except FileNotFoundError:\n",
    "    Xy['ents'] = Xy.title.progress_apply(str_to_ents)\n",
    "    Xy['ents_fraction'] = Xy['ents'].apply(lambda x: x[1])\n",
    "    Xy['ents'] = Xy['ents'].apply(lambda x: x[0])\n",
    "    Xy.to_csv(f'{DATASETS_PATH}/Xy_ents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем полученные данные об именованных сущностях к числовому представлению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ee5c992bc144aab1b8617729177b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=306402.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>title</th>\n",
       "      <th>views_num</th>\n",
       "      <th>y</th>\n",
       "      <th>ents</th>\n",
       "      <th>ents_fraction</th>\n",
       "      <th>PER</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "      <th>OBJ</th>\n",
       "      <th>...</th>\n",
       "      <th>SITE</th>\n",
       "      <th>ANNOUNCE</th>\n",
       "      <th>MATH</th>\n",
       "      <th>GAME</th>\n",
       "      <th>NEWS</th>\n",
       "      <th>CONF</th>\n",
       "      <th>COND</th>\n",
       "      <th>APP</th>\n",
       "      <th>LIB</th>\n",
       "      <th>FRAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006861</td>\n",
       "      <td>Blackbox-сканеры в процессе оценки безопасност...</td>\n",
       "      <td>0.023319</td>\n",
       "      <td>1.959235</td>\n",
       "      <td>[DANGER]</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006972</td>\n",
       "      <td>Инструменты управления командой разработки на ...</td>\n",
       "      <td>0.058947</td>\n",
       "      <td>2.606826</td>\n",
       "      <td>[OBJ, OBJ, PUNCT, TYPE]</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006989</td>\n",
       "      <td>Стоит поиграть: обзор игры 7 Billion Humans</td>\n",
       "      <td>0.081565</td>\n",
       "      <td>2.938459</td>\n",
       "      <td>[TYPE, PUNCT, TYPE, OS]</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007087</td>\n",
       "      <td>Как снизить расходы на разработку программного...</td>\n",
       "      <td>0.078663</td>\n",
       "      <td>2.899126</td>\n",
       "      <td>[DANGER, DANGER, PUNCT]</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007103</td>\n",
       "      <td>Моя история в IT: от любви к математике до меж...</td>\n",
       "      <td>0.071457</td>\n",
       "      <td>2.783585</td>\n",
       "      <td>[TYPE, PUNCT, TYPE, VERSION, TYPE]</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta                                              title  views_num  \\\n",
       "0   0.006861  Blackbox-сканеры в процессе оценки безопасност...   0.023319   \n",
       "1   0.006972  Инструменты управления командой разработки на ...   0.058947   \n",
       "2   0.006989        Стоит поиграть: обзор игры 7 Billion Humans   0.081565   \n",
       "3   0.007087  Как снизить расходы на разработку программного...   0.078663   \n",
       "4   0.007103  Моя история в IT: от любви к математике до меж...   0.071457   \n",
       "\n",
       "          y                                ents  ents_fraction  PER  ORG  LOC  \\\n",
       "0  1.959235                            [DANGER]       0.517241    0    0    0   \n",
       "1  2.606826             [OBJ, OBJ, PUNCT, TYPE]       0.935897    0    0    0   \n",
       "2  2.938459             [TYPE, PUNCT, TYPE, OS]       0.604651    0    0    0   \n",
       "3  2.899126             [DANGER, DANGER, PUNCT]       0.932203    0    0    0   \n",
       "4  2.783585  [TYPE, PUNCT, TYPE, VERSION, TYPE]       0.829787    0    0    0   \n",
       "\n",
       "   OBJ  ...  SITE  ANNOUNCE  MATH  GAME  NEWS  CONF  COND  APP  LIB  FRAME  \n",
       "0    0  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "1    2  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "2    0  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "3    0  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "4    0  ...     0         0     0     0     0     0     0    0    0      0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в файле tags.json хранятся данные \n",
    "with open(f'{DATASETS_PATH}/tags.json') as f:\n",
    "    tags = json.load(f)\n",
    "\n",
    "# определим, какие сущности мы зарезервировали\n",
    "tag_names = [list(d.keys())[0] for d in tags]\n",
    "\n",
    "def ents_to_array(ents_list):\n",
    "    '''Преобразует список именованных сущностей\n",
    "    для одного заголовка в массив чисел,\n",
    "    где индекс соответствует номеру сущности,\n",
    "    а число - количеству появлений в заголовке'''\n",
    "    line = [0]*len(tag_names)\n",
    "    for t in ents_list:\n",
    "        try:\n",
    "            i = tag_names.index(t)\n",
    "            line[i] += 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return np.array(line, dtype=np.uint8)\n",
    "\n",
    "ents_array = Xy.ents.progress_apply(ents_to_array)\n",
    "data = np.array(ents_array.to_list())\n",
    "tmp = pd.DataFrame(data, columns=tag_names)\n",
    "Xy = pd.concat([Xy, tmp], axis = 1)\n",
    "Xy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на корреляцию признаков и числа просмотров `views_num` (без нелинейных преобразований `y`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "views_num        1.000000\n",
       "TYPE             0.067021\n",
       "AUD              0.059252\n",
       "NUM              0.058857\n",
       "TECH             0.033479\n",
       "ADV              0.028049\n",
       "OS               0.027734\n",
       "TODO             0.027263\n",
       "ents_fraction    0.025298\n",
       "APP              0.024423\n",
       "EFFORT           0.022167\n",
       "COND             0.020695\n",
       "DEVICE           0.020341\n",
       "EMO              0.015683\n",
       "MATH             0.014419\n",
       "OBJ              0.014397\n",
       "STRUCT           0.014030\n",
       "PART             0.013372\n",
       "LANG             0.012273\n",
       "LIB              0.009814\n",
       "FRAME            0.009645\n",
       "ORG              0.004831\n",
       "GAME             0.001097\n",
       "PER             -0.002634\n",
       "NEWS            -0.004132\n",
       "SITE            -0.004590\n",
       "ANNOUNCE        -0.004949\n",
       "CONF            -0.009781\n",
       "DANGER          -0.010112\n",
       "LOC             -0.013116\n",
       "PROGRAM         -0.018553\n",
       "timedelta       -0.144619\n",
       "Name: views_num, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = Xy.drop(columns=['y']).corr()\n",
    "correlations['views_num'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Относительно тегов мы можем предположить, что указание типа (`TYPE`),  используемой технологии (`TECH`), целевой аудитории `AUD` и совершаемого действия (`TODO`) обычно приводят к увеличению числа просмотров.\n",
    "\n",
    "Указание опасности (`DANGER`), организации, персоны, локации (`ORG`, `PER`, `LOC`), конкретной программы (`PROGRAM`), конференции (`CONF`),видимо, в большей мере относятся к новостям, которые быстро теряют актуальности. Поэтому такие атрибуты связаны с уменьшением количества просмотров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.drop(columns=['title', 'views_num', 'ents', 'y'])\n",
    "y = Xy.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сами корреляции коэффициенты корреляции в абсолютном значении невелики. Поэтому большее внимание надо отдавать языковой модели. Предварительно попробуем поискать композитные фичи, используя пары и тройки столбцов с тегами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ents = X.drop(columns=['timedelta', 'ents_fraction'])\n",
    "from itertools import combinations\n",
    "\n",
    "cc2 = list(combinations(X_ents.columns,2))\n",
    "X_ents2 = pd.concat([X_ents[c[0]].add(X_ents[c[1]]) for c in cc2],\n",
    "          axis=1, keys=cc2)\n",
    "\n",
    "cc3 = list(combinations(X_ents.columns,3))\n",
    "X_ents3 = pd.concat([X_ents[c[0]].add(X_ents[c[1]]).add(X_ents[c[2]]) for c in cc3],\n",
    "          axis=1, keys=cc3)\n",
    "\n",
    "X_ents2.columns = X_ents2.columns.map('_'.join)\n",
    "X_ents3.columns = X_ents3.columns.map('_'.join)\n",
    "X_ents = pd.concat([X, X_ents2, X_ents3, Xy['views_num']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "X_ents = X_ents.fillna(0)\n",
    "X_ents['BOOL'] = X.ents_fraction.apply(lambda x: x == 0)\n",
    "for col in X_ents.drop(columns=['views_num', 'timedelta', 'ents_fraction']).columns:\n",
    "    d[col] = stats.pearsonr(X_ents['views_num'], X_ents[col])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list, value_list = [], []\n",
    "\n",
    "for key in d:\n",
    "    ner_list.append(set(key.split('_')))\n",
    "    value_list.append(d[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_cor = pd.DataFrame.from_dict({'NER': ner_list, 'VALUE': value_list})\n",
    "df_ner_cor.to_csv(f'{DATASETS_PATH}/df_ner_cor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>{BOOL}</td>\n",
       "      <td>-0.029062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>{PROGRAM, LOC, CONF}</td>\n",
       "      <td>-0.023704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>{ANNOUNCE, PROGRAM, LOC}</td>\n",
       "      <td>-0.022861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>{NEWS, PROGRAM, LOC}</td>\n",
       "      <td>-0.022713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>{DANGER, PROGRAM, LOC}</td>\n",
       "      <td>-0.022632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>{TYPE, TECH, AUD}</td>\n",
       "      <td>0.090052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>{TYPE, AUD, OS}</td>\n",
       "      <td>0.090362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>{TYPE, AUD, ADV}</td>\n",
       "      <td>0.090488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>{TYPE, AUD, TODO}</td>\n",
       "      <td>0.091366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>{TYPE, AUD, NUM}</td>\n",
       "      <td>0.096743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NER     VALUE\n",
       "4089                    {BOOL} -0.029062\n",
       "1429      {PROGRAM, LOC, CONF} -0.023704\n",
       "1425  {ANNOUNCE, PROGRAM, LOC} -0.022861\n",
       "1428      {NEWS, PROGRAM, LOC} -0.022713\n",
       "1306    {DANGER, PROGRAM, LOC} -0.022632\n",
       "...                        ...       ...\n",
       "1798         {TYPE, TECH, AUD}  0.090052\n",
       "1799           {TYPE, AUD, OS}  0.090362\n",
       "1796          {TYPE, AUD, ADV}  0.090488\n",
       "1794         {TYPE, AUD, TODO}  0.091366\n",
       "1789          {TYPE, AUD, NUM}  0.096743\n",
       "\n",
       "[4090 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner_cor.sort_values(by='VALUE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метке `BOOL` соответствует полное отсутствие каких-либо сущностей. Таким образом, хотя бы минимальное соответствие, даже худшим по корреляциям из меток, лучше, чем ничего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Обучение регрессионной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы привели текстовые данные к числовому представлению и теперь можем заняться задачей регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ents.drop(columns=['views_num']), y,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении используем структуру `Pool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 10000,\n",
    "    'learning_rate': 0.01,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'early_stopping_rounds': 100,\n",
    "    'use_best_model': True\n",
    "}\n",
    "\n",
    "def fit_model(X_train, y_train, X_test, y_test, catboost_params):\n",
    "    train_pool = Pool(data = X_train,\n",
    "                      label = y_train)\n",
    "\n",
    "    validation_pool = Pool(data = X_test,\n",
    "                           label = y_test)\n",
    "\n",
    "    model = CatBoostRegressor(**catboost_params)\n",
    "\n",
    "    return model.fit(train_pool,\n",
    "                     eval_set=validation_pool,\n",
    "                     verbose=100)\n",
    "\n",
    "\n",
    "model = fit_model(X_train, y_train,\n",
    "                  X_test, y_test,\n",
    "                  catboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE(model.predict(X_test), y_test))\n",
    "plt.scatter(model.predict(X_test), y_test, s=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вполне ожидаемо (и прискорбно), но регресионная модель обучается довольно слабо: на число просмотров оказывают влияния множество иных факторов, а не только сами сущности.\n",
    "\n",
    "Использование трансформерной модели или других моделей, работающих с сутью текста, повысило бы качество, но усложнило бы коррекцию заголовка пользователем: балл оценки в таком случае сложно интерпретируется, возможны только действия \"наугад\". Однако такое решение можно использовать в будущем для генеративного подхода поиска заголовка.\n",
    "\n",
    "Поэтому мы воспользуемся подходом программного определения правил, исходя из лучших сочетаний сущностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Упрощенная корреляционная модель\n",
    "\n",
    "Напишем функцию, которая принимает на вход строку, а на выходе возвращает рекомендации для коррекции заголовка. Для этого нам понадобится несколько вспомогательных функций.\n",
    "\n",
    "Проведем нормировку между 0 и 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_cor.VALUE = minmax_scale(df_ner_cor.VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{PER}</td>\n",
       "      <td>0.210073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{ORG}</td>\n",
       "      <td>0.269408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{LOC}</td>\n",
       "      <td>0.126752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{OBJ}</td>\n",
       "      <td>0.345451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{AUD}</td>\n",
       "      <td>0.701996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>{COND, APP, LIB}</td>\n",
       "      <td>0.479847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>{COND, APP, FRAME}</td>\n",
       "      <td>0.481229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>{COND, FRAME, LIB}</td>\n",
       "      <td>0.408821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>{APP, FRAME, LIB}</td>\n",
       "      <td>0.432201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>{BOOL}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NER     VALUE\n",
       "0                  {PER}  0.210073\n",
       "1                  {ORG}  0.269408\n",
       "2                  {LOC}  0.126752\n",
       "3                  {OBJ}  0.345451\n",
       "4                  {AUD}  0.701996\n",
       "...                  ...       ...\n",
       "4085    {COND, APP, LIB}  0.479847\n",
       "4086  {COND, APP, FRAME}  0.481229\n",
       "4087  {COND, FRAME, LIB}  0.408821\n",
       "4088   {APP, FRAME, LIB}  0.432201\n",
       "4089              {BOOL}  0.000000\n",
       "\n",
       "[4090 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_list_to_value(ner_list, df=df_ner_cor):\n",
    "    return value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
